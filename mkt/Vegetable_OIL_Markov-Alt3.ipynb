{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5uCxyx957cMM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Math #para escrever equações \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFuxrtroM9X8",
    "outputId": "05c91eb7-e866-4699-f29a-7d91653c94f1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from xmlrpc.client import Boolean\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quantecon as qe\n",
    "\n",
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "# logging.basicConfig(level=logging.DEBUG) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Igyu8UnuS10s"
   },
   "outputs": [],
   "source": [
    "RANDOM_SIZE   = 1000000\n",
    "RANDOM_SIZE   = 10000\n",
    "QTD_BINS      = 3\n",
    "TEST_SIZE     = 0.05\n",
    "RANDOM_STATE  = 2022\n",
    "PREDITOR                 = ['vegetable-oil_price', 'vegetable-oil_production', 'vegetable-oil_exports']\n",
    "PREDITOR_DIRECTIONS      = ['vegetable-oil_price', 'vegetable-oil_production', 'vegetable-oil_exports']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29SMRFn5709O"
   },
   "source": [
    "- https://raw.githubusercontent.com/fkfouri/vegetable_oil_mkt/master/dataset/__by_month_commodity_types.csv\n",
    "- https://raw.githubusercontent.com/fkfouri/vegetable_oil_mkt/master/dataset/__by_month_vegetable_oil.csv\n",
    "- https://raw.githubusercontent.com/fkfouri/vegetable_oil_mkt/master/dataset/__by_month_full.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWY0lj_T9XUR"
   },
   "source": [
    "# Mercado de Oleo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-n5NC_CMbA7"
   },
   "source": [
    "## Dataset Completo\n",
    "- USDA por comodity\n",
    "- USDA Agrupado por Oleo Vegetal\n",
    "- OECD Agrupado\n",
    "- FAO Index Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "ZB1v_-LK7lKF",
    "outputId": "cae3ae0b-396a-47e8-ec3a-029136aab2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 139)\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 428 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>coconut_beginning-stocks</th>\n",
       "      <th>coconut_crush</th>\n",
       "      <th>coconut_domestic-consumption</th>\n",
       "      <th>coconut_ending-stocks</th>\n",
       "      <th>coconut_exports</th>\n",
       "      <th>coconut_feed-waste-dom-cons</th>\n",
       "      <th>coconut_food-use-dom-cons</th>\n",
       "      <th>coconut_imports</th>\n",
       "      <th>coconut_industrial-dom-cons</th>\n",
       "      <th>...</th>\n",
       "      <th>vegetable-oil_total-supply</th>\n",
       "      <th>vegetable-oil_oecd_consumption</th>\n",
       "      <th>vegetable-oil_oecd_ending-stocks</th>\n",
       "      <th>vegetable-oil_oecd_exports</th>\n",
       "      <th>vegetable-oil_oecd_food</th>\n",
       "      <th>vegetable-oil_oecd_food-fat-availability</th>\n",
       "      <th>vegetable-oil_oecd_human-consumption-per-capita</th>\n",
       "      <th>vegetable-oil_oecd_imports</th>\n",
       "      <th>vegetable-oil_oecd_other-use</th>\n",
       "      <th>vegetable-oil_oecd_production</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7273.770</td>\n",
       "      <td>844.920</td>\n",
       "      <td>2541.320</td>\n",
       "      <td>6179.990</td>\n",
       "      <td>2.240</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2490.870</td>\n",
       "      <td>1088.770</td>\n",
       "      <td>7469.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7298.970</td>\n",
       "      <td>849.930</td>\n",
       "      <td>2562.660</td>\n",
       "      <td>6190.320</td>\n",
       "      <td>2.240</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2504.980</td>\n",
       "      <td>1098.620</td>\n",
       "      <td>7494.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7324.160</td>\n",
       "      <td>854.950</td>\n",
       "      <td>2584.010</td>\n",
       "      <td>6200.660</td>\n",
       "      <td>2.240</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2519.100</td>\n",
       "      <td>1108.460</td>\n",
       "      <td>7519.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7349.360</td>\n",
       "      <td>859.960</td>\n",
       "      <td>2605.360</td>\n",
       "      <td>6211.000</td>\n",
       "      <td>2.240</td>\n",
       "      <td>1.030</td>\n",
       "      <td>2533.210</td>\n",
       "      <td>1118.310</td>\n",
       "      <td>7543.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7374.550</td>\n",
       "      <td>864.970</td>\n",
       "      <td>2626.710</td>\n",
       "      <td>6221.340</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.030</td>\n",
       "      <td>2547.320</td>\n",
       "      <td>1128.150</td>\n",
       "      <td>7568.420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reference  coconut_beginning-stocks  coconut_crush  \\\n",
       "date                                                            \n",
       "2000-01-31       NaN                       NaN            NaN   \n",
       "2000-02-29       NaN                       NaN            NaN   \n",
       "2000-03-31       NaN                       NaN            NaN   \n",
       "2000-04-30       NaN                       NaN            NaN   \n",
       "2000-05-31       NaN                       NaN            NaN   \n",
       "\n",
       "            coconut_domestic-consumption  coconut_ending-stocks  \\\n",
       "date                                                              \n",
       "2000-01-31                           NaN                    NaN   \n",
       "2000-02-29                           NaN                    NaN   \n",
       "2000-03-31                           NaN                    NaN   \n",
       "2000-04-30                           NaN                    NaN   \n",
       "2000-05-31                           NaN                    NaN   \n",
       "\n",
       "            coconut_exports  coconut_feed-waste-dom-cons  \\\n",
       "date                                                       \n",
       "2000-01-31              NaN                          NaN   \n",
       "2000-02-29              NaN                          NaN   \n",
       "2000-03-31              NaN                          NaN   \n",
       "2000-04-30              NaN                          NaN   \n",
       "2000-05-31              NaN                          NaN   \n",
       "\n",
       "            coconut_food-use-dom-cons  coconut_imports  \\\n",
       "date                                                     \n",
       "2000-01-31                        NaN              NaN   \n",
       "2000-02-29                        NaN              NaN   \n",
       "2000-03-31                        NaN              NaN   \n",
       "2000-04-30                        NaN              NaN   \n",
       "2000-05-31                        NaN              NaN   \n",
       "\n",
       "            coconut_industrial-dom-cons  ...  vegetable-oil_total-supply  \\\n",
       "date                                     ...                               \n",
       "2000-01-31                          NaN  ...                         NaN   \n",
       "2000-02-29                          NaN  ...                         NaN   \n",
       "2000-03-31                          NaN  ...                         NaN   \n",
       "2000-04-30                          NaN  ...                         NaN   \n",
       "2000-05-31                          NaN  ...                         NaN   \n",
       "\n",
       "            vegetable-oil_oecd_consumption  vegetable-oil_oecd_ending-stocks  \\\n",
       "date                                                                           \n",
       "2000-01-31                        7273.770                           844.920   \n",
       "2000-02-29                        7298.970                           849.930   \n",
       "2000-03-31                        7324.160                           854.950   \n",
       "2000-04-30                        7349.360                           859.960   \n",
       "2000-05-31                        7374.550                           864.970   \n",
       "\n",
       "            vegetable-oil_oecd_exports  vegetable-oil_oecd_food  \\\n",
       "date                                                              \n",
       "2000-01-31                    2541.320                 6179.990   \n",
       "2000-02-29                    2562.660                 6190.320   \n",
       "2000-03-31                    2584.010                 6200.660   \n",
       "2000-04-30                    2605.360                 6211.000   \n",
       "2000-05-31                    2626.710                 6221.340   \n",
       "\n",
       "            vegetable-oil_oecd_food-fat-availability  \\\n",
       "date                                                   \n",
       "2000-01-31                                     2.240   \n",
       "2000-02-29                                     2.240   \n",
       "2000-03-31                                     2.240   \n",
       "2000-04-30                                     2.240   \n",
       "2000-05-31                                     2.250   \n",
       "\n",
       "            vegetable-oil_oecd_human-consumption-per-capita  \\\n",
       "date                                                          \n",
       "2000-01-31                                            1.020   \n",
       "2000-02-29                                            1.020   \n",
       "2000-03-31                                            1.020   \n",
       "2000-04-30                                            1.030   \n",
       "2000-05-31                                            1.030   \n",
       "\n",
       "            vegetable-oil_oecd_imports  vegetable-oil_oecd_other-use  \\\n",
       "date                                                                   \n",
       "2000-01-31                    2490.870                      1088.770   \n",
       "2000-02-29                    2504.980                      1098.620   \n",
       "2000-03-31                    2519.100                      1108.460   \n",
       "2000-04-30                    2533.210                      1118.310   \n",
       "2000-05-31                    2547.320                      1128.150   \n",
       "\n",
       "            vegetable-oil_oecd_production  \n",
       "date                                       \n",
       "2000-01-31                       7469.760  \n",
       "2000-02-29                       7494.420  \n",
       "2000-03-31                       7519.090  \n",
       "2000-04-30                       7543.750  \n",
       "2000-05-31                       7568.420  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataset():\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/fkfouri/vegetable_oil_mkt/master/dataset/__by_month_full.csv')\n",
    "    print(df.shape)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by=['date'], ascending=[True], inplace=True)\n",
    "    df.set_index(['date'], inplace=True)\n",
    "    return df\n",
    "\n",
    "%time df_full = get_dataset()\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RU6z_LtW-OzH",
    "outputId": "2163ac46-6440-4130-9017-3155b81af1d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 266 entries, 2000-01-31 to 2022-02-28\n",
      "Columns: 138 entries, reference to vegetable-oil_oecd_production\n",
      "dtypes: float64(137), object(1)\n",
      "memory usage: 288.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBvq3qcJBbR1",
    "outputId": "49ddf93a-0f7c-4fe6-a3f3-d6c6aa682c46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference                                           object\n",
       "coconut_beginning-stocks                           float64\n",
       "coconut_crush                                      float64\n",
       "coconut_domestic-consumption                       float64\n",
       "coconut_ending-stocks                              float64\n",
       "                                                    ...   \n",
       "vegetable-oil_oecd_food-fat-availability           float64\n",
       "vegetable-oil_oecd_human-consumption-per-capita    float64\n",
       "vegetable-oil_oecd_imports                         float64\n",
       "vegetable-oil_oecd_other-use                       float64\n",
       "vegetable-oil_oecd_production                      float64\n",
       "Length: 138, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2GRmDyXB2HB",
    "outputId": "e4d9ce38-ae79-4675-d730-97df0cdd4707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 26 | ['coconut_exports', 'coconut_price', 'coconut_production', 'palm-kernel_exports', 'palm-kernel_price', 'palm-kernel_production', 'palm_exports', 'palm_price', 'palm_production', 'peanut_exports', 'peanut_price', 'peanut_production', 'rapeseed_exports', 'rapeseed_price', 'rapeseed_production', 'soybean_exports', 'soybean_price', 'soybean_production', 'sunflower_exports', 'sunflower_price', 'sunflower_production', 'vegetable-oil_exports', 'vegetable-oil_price', 'vegetable-oil_production', 'vegetable-oil_oecd_exports', 'vegetable-oil_oecd_production']\n",
      "============================================================\n",
      "prices: 8 | ['coconut_price', 'palm-kernel_price', 'palm_price', 'peanut_price', 'rapeseed_price', 'soybean_price', 'sunflower_price', 'vegetable-oil_price']\n"
     ]
    }
   ],
   "source": [
    "#Identificacao de colunas/atributos\n",
    "features = [x for x in df_full.columns if ('exports' in x or 'production' in x or 'price' in x) and not ('olive' in x or 'cottonseed' in x) ]\n",
    "prices   = [x for x in df_full.columns if 'price' in x and 'groundnut' not in x  ]\n",
    "\n",
    "print(f'features: {len(features)} | {features}')\n",
    "print(\"==\" * 30)\n",
    "print(f'prices: {len(prices)} | {prices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "id": "XFafnbB3CVUe",
    "outputId": "301748c3-b4c3-43ea-80e1-7d18b9dd2337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 26)\n",
      "(234, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coconut_exports</th>\n",
       "      <th>coconut_price</th>\n",
       "      <th>coconut_production</th>\n",
       "      <th>palm-kernel_exports</th>\n",
       "      <th>palm-kernel_price</th>\n",
       "      <th>palm-kernel_production</th>\n",
       "      <th>palm_exports</th>\n",
       "      <th>palm_price</th>\n",
       "      <th>palm_production</th>\n",
       "      <th>peanut_exports</th>\n",
       "      <th>...</th>\n",
       "      <th>soybean_price</th>\n",
       "      <th>soybean_production</th>\n",
       "      <th>sunflower_exports</th>\n",
       "      <th>sunflower_price</th>\n",
       "      <th>sunflower_production</th>\n",
       "      <th>vegetable-oil_exports</th>\n",
       "      <th>vegetable-oil_price</th>\n",
       "      <th>vegetable-oil_production</th>\n",
       "      <th>vegetable-oil_oecd_exports</th>\n",
       "      <th>vegetable-oil_oecd_production</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-02-28</th>\n",
       "      <td>148.440</td>\n",
       "      <td>376.000</td>\n",
       "      <td>255.940</td>\n",
       "      <td>130.470</td>\n",
       "      <td>356.000</td>\n",
       "      <td>264.710</td>\n",
       "      <td>1527.920</td>\n",
       "      <td>352.980</td>\n",
       "      <td>2146.310</td>\n",
       "      <td>17.030</td>\n",
       "      <td>...</td>\n",
       "      <td>364.920</td>\n",
       "      <td>3204.320</td>\n",
       "      <td>166.180</td>\n",
       "      <td>578.000</td>\n",
       "      <td>620.920</td>\n",
       "      <td>3312.180</td>\n",
       "      <td>47.786</td>\n",
       "      <td>8559.630</td>\n",
       "      <td>2986.310</td>\n",
       "      <td>7954.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-31</th>\n",
       "      <td>148.040</td>\n",
       "      <td>366.000</td>\n",
       "      <td>255.830</td>\n",
       "      <td>130.830</td>\n",
       "      <td>353.240</td>\n",
       "      <td>266.520</td>\n",
       "      <td>1543.880</td>\n",
       "      <td>359.000</td>\n",
       "      <td>2162.830</td>\n",
       "      <td>16.580</td>\n",
       "      <td>...</td>\n",
       "      <td>359.210</td>\n",
       "      <td>3222.400</td>\n",
       "      <td>168.850</td>\n",
       "      <td>557.000</td>\n",
       "      <td>625.580</td>\n",
       "      <td>3339.800</td>\n",
       "      <td>47.622</td>\n",
       "      <td>8591.720</td>\n",
       "      <td>3014.280</td>\n",
       "      <td>7983.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>147.640</td>\n",
       "      <td>411.000</td>\n",
       "      <td>255.720</td>\n",
       "      <td>131.190</td>\n",
       "      <td>405.000</td>\n",
       "      <td>268.330</td>\n",
       "      <td>1559.830</td>\n",
       "      <td>360.070</td>\n",
       "      <td>2179.360</td>\n",
       "      <td>16.140</td>\n",
       "      <td>...</td>\n",
       "      <td>370.860</td>\n",
       "      <td>3240.470</td>\n",
       "      <td>171.530</td>\n",
       "      <td>552.000</td>\n",
       "      <td>630.250</td>\n",
       "      <td>3367.440</td>\n",
       "      <td>48.969</td>\n",
       "      <td>8623.810</td>\n",
       "      <td>3042.260</td>\n",
       "      <td>8012.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-31</th>\n",
       "      <td>147.240</td>\n",
       "      <td>420.000</td>\n",
       "      <td>255.610</td>\n",
       "      <td>131.560</td>\n",
       "      <td>418.300</td>\n",
       "      <td>270.150</td>\n",
       "      <td>1575.790</td>\n",
       "      <td>384.910</td>\n",
       "      <td>2195.890</td>\n",
       "      <td>15.690</td>\n",
       "      <td>...</td>\n",
       "      <td>399.890</td>\n",
       "      <td>3258.550</td>\n",
       "      <td>174.200</td>\n",
       "      <td>574.000</td>\n",
       "      <td>634.920</td>\n",
       "      <td>3395.080</td>\n",
       "      <td>51.641</td>\n",
       "      <td>8655.950</td>\n",
       "      <td>3070.240</td>\n",
       "      <td>8041.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>146.830</td>\n",
       "      <td>446.000</td>\n",
       "      <td>255.500</td>\n",
       "      <td>131.920</td>\n",
       "      <td>439.000</td>\n",
       "      <td>271.960</td>\n",
       "      <td>1591.750</td>\n",
       "      <td>426.130</td>\n",
       "      <td>2212.420</td>\n",
       "      <td>15.250</td>\n",
       "      <td>...</td>\n",
       "      <td>456.810</td>\n",
       "      <td>3276.620</td>\n",
       "      <td>176.880</td>\n",
       "      <td>595.000</td>\n",
       "      <td>639.580</td>\n",
       "      <td>3422.710</td>\n",
       "      <td>55.804</td>\n",
       "      <td>8688.040</td>\n",
       "      <td>3098.220</td>\n",
       "      <td>8070.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>157.080</td>\n",
       "      <td>1493.640</td>\n",
       "      <td>290.610</td>\n",
       "      <td>276.780</td>\n",
       "      <td>1341.140</td>\n",
       "      <td>716.470</td>\n",
       "      <td>4092.220</td>\n",
       "      <td>1141.820</td>\n",
       "      <td>6229.440</td>\n",
       "      <td>35.640</td>\n",
       "      <td>...</td>\n",
       "      <td>1433.940</td>\n",
       "      <td>6354.170</td>\n",
       "      <td>988.220</td>\n",
       "      <td>1355.691</td>\n",
       "      <td>1703.690</td>\n",
       "      <td>7821.270</td>\n",
       "      <td>165.862</td>\n",
       "      <td>18894.320</td>\n",
       "      <td>7325.470</td>\n",
       "      <td>18174.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>158.080</td>\n",
       "      <td>1485.000</td>\n",
       "      <td>291.080</td>\n",
       "      <td>278.380</td>\n",
       "      <td>1427.270</td>\n",
       "      <td>718.600</td>\n",
       "      <td>4103.190</td>\n",
       "      <td>1181.380</td>\n",
       "      <td>6246.960</td>\n",
       "      <td>35.020</td>\n",
       "      <td>...</td>\n",
       "      <td>1398.750</td>\n",
       "      <td>6350.750</td>\n",
       "      <td>994.670</td>\n",
       "      <td>1309.519</td>\n",
       "      <td>1717.600</td>\n",
       "      <td>7837.790</td>\n",
       "      <td>168.571</td>\n",
       "      <td>18923.870</td>\n",
       "      <td>7328.510</td>\n",
       "      <td>18207.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31</th>\n",
       "      <td>159.080</td>\n",
       "      <td>1922.860</td>\n",
       "      <td>291.560</td>\n",
       "      <td>279.970</td>\n",
       "      <td>1818.330</td>\n",
       "      <td>720.740</td>\n",
       "      <td>4114.150</td>\n",
       "      <td>1310.250</td>\n",
       "      <td>6264.470</td>\n",
       "      <td>34.400</td>\n",
       "      <td>...</td>\n",
       "      <td>1483.520</td>\n",
       "      <td>6347.330</td>\n",
       "      <td>1001.110</td>\n",
       "      <td>1420.528</td>\n",
       "      <td>1731.510</td>\n",
       "      <td>7854.300</td>\n",
       "      <td>184.837</td>\n",
       "      <td>18953.420</td>\n",
       "      <td>7331.560</td>\n",
       "      <td>18241.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>160.080</td>\n",
       "      <td>1960.680</td>\n",
       "      <td>292.030</td>\n",
       "      <td>281.570</td>\n",
       "      <td>2050.230</td>\n",
       "      <td>722.870</td>\n",
       "      <td>4125.120</td>\n",
       "      <td>1340.650</td>\n",
       "      <td>6281.990</td>\n",
       "      <td>33.780</td>\n",
       "      <td>...</td>\n",
       "      <td>1442.960</td>\n",
       "      <td>6343.920</td>\n",
       "      <td>1007.560</td>\n",
       "      <td>1415.617</td>\n",
       "      <td>1745.420</td>\n",
       "      <td>7870.820</td>\n",
       "      <td>184.555</td>\n",
       "      <td>18982.970</td>\n",
       "      <td>7334.600</td>\n",
       "      <td>18274.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>161.080</td>\n",
       "      <td>1695.710</td>\n",
       "      <td>292.500</td>\n",
       "      <td>283.170</td>\n",
       "      <td>1861.430</td>\n",
       "      <td>725.000</td>\n",
       "      <td>4136.080</td>\n",
       "      <td>1270.290</td>\n",
       "      <td>6299.500</td>\n",
       "      <td>33.170</td>\n",
       "      <td>...</td>\n",
       "      <td>1411.210</td>\n",
       "      <td>6340.500</td>\n",
       "      <td>1014.000</td>\n",
       "      <td>1361.831</td>\n",
       "      <td>1759.330</td>\n",
       "      <td>7887.340</td>\n",
       "      <td>178.505</td>\n",
       "      <td>19012.500</td>\n",
       "      <td>7337.650</td>\n",
       "      <td>18307.580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            coconut_exports  coconut_price  coconut_production  \\\n",
       "date                                                             \n",
       "2002-02-28          148.440        376.000             255.940   \n",
       "2002-03-31          148.040        366.000             255.830   \n",
       "2002-04-30          147.640        411.000             255.720   \n",
       "2002-05-31          147.240        420.000             255.610   \n",
       "2002-06-30          146.830        446.000             255.500   \n",
       "...                     ...            ...                 ...   \n",
       "2021-08-31          157.080       1493.640             290.610   \n",
       "2021-09-30          158.080       1485.000             291.080   \n",
       "2021-10-31          159.080       1922.860             291.560   \n",
       "2021-11-30          160.080       1960.680             292.030   \n",
       "2021-12-31          161.080       1695.710             292.500   \n",
       "\n",
       "            palm-kernel_exports  palm-kernel_price  palm-kernel_production  \\\n",
       "date                                                                         \n",
       "2002-02-28              130.470            356.000                 264.710   \n",
       "2002-03-31              130.830            353.240                 266.520   \n",
       "2002-04-30              131.190            405.000                 268.330   \n",
       "2002-05-31              131.560            418.300                 270.150   \n",
       "2002-06-30              131.920            439.000                 271.960   \n",
       "...                         ...                ...                     ...   \n",
       "2021-08-31              276.780           1341.140                 716.470   \n",
       "2021-09-30              278.380           1427.270                 718.600   \n",
       "2021-10-31              279.970           1818.330                 720.740   \n",
       "2021-11-30              281.570           2050.230                 722.870   \n",
       "2021-12-31              283.170           1861.430                 725.000   \n",
       "\n",
       "            palm_exports  palm_price  palm_production  peanut_exports  ...  \\\n",
       "date                                                                   ...   \n",
       "2002-02-28      1527.920     352.980         2146.310          17.030  ...   \n",
       "2002-03-31      1543.880     359.000         2162.830          16.580  ...   \n",
       "2002-04-30      1559.830     360.070         2179.360          16.140  ...   \n",
       "2002-05-31      1575.790     384.910         2195.890          15.690  ...   \n",
       "2002-06-30      1591.750     426.130         2212.420          15.250  ...   \n",
       "...                  ...         ...              ...             ...  ...   \n",
       "2021-08-31      4092.220    1141.820         6229.440          35.640  ...   \n",
       "2021-09-30      4103.190    1181.380         6246.960          35.020  ...   \n",
       "2021-10-31      4114.150    1310.250         6264.470          34.400  ...   \n",
       "2021-11-30      4125.120    1340.650         6281.990          33.780  ...   \n",
       "2021-12-31      4136.080    1270.290         6299.500          33.170  ...   \n",
       "\n",
       "            soybean_price  soybean_production  sunflower_exports  \\\n",
       "date                                                               \n",
       "2002-02-28        364.920            3204.320            166.180   \n",
       "2002-03-31        359.210            3222.400            168.850   \n",
       "2002-04-30        370.860            3240.470            171.530   \n",
       "2002-05-31        399.890            3258.550            174.200   \n",
       "2002-06-30        456.810            3276.620            176.880   \n",
       "...                   ...                 ...                ...   \n",
       "2021-08-31       1433.940            6354.170            988.220   \n",
       "2021-09-30       1398.750            6350.750            994.670   \n",
       "2021-10-31       1483.520            6347.330           1001.110   \n",
       "2021-11-30       1442.960            6343.920           1007.560   \n",
       "2021-12-31       1411.210            6340.500           1014.000   \n",
       "\n",
       "            sunflower_price  sunflower_production  vegetable-oil_exports  \\\n",
       "date                                                                       \n",
       "2002-02-28          578.000               620.920               3312.180   \n",
       "2002-03-31          557.000               625.580               3339.800   \n",
       "2002-04-30          552.000               630.250               3367.440   \n",
       "2002-05-31          574.000               634.920               3395.080   \n",
       "2002-06-30          595.000               639.580               3422.710   \n",
       "...                     ...                   ...                    ...   \n",
       "2021-08-31         1355.691              1703.690               7821.270   \n",
       "2021-09-30         1309.519              1717.600               7837.790   \n",
       "2021-10-31         1420.528              1731.510               7854.300   \n",
       "2021-11-30         1415.617              1745.420               7870.820   \n",
       "2021-12-31         1361.831              1759.330               7887.340   \n",
       "\n",
       "            vegetable-oil_price  vegetable-oil_production  \\\n",
       "date                                                        \n",
       "2002-02-28               47.786                  8559.630   \n",
       "2002-03-31               47.622                  8591.720   \n",
       "2002-04-30               48.969                  8623.810   \n",
       "2002-05-31               51.641                  8655.950   \n",
       "2002-06-30               55.804                  8688.040   \n",
       "...                         ...                       ...   \n",
       "2021-08-31              165.862                 18894.320   \n",
       "2021-09-30              168.571                 18923.870   \n",
       "2021-10-31              184.837                 18953.420   \n",
       "2021-11-30              184.555                 18982.970   \n",
       "2021-12-31              178.505                 19012.500   \n",
       "\n",
       "            vegetable-oil_oecd_exports  vegetable-oil_oecd_production  \n",
       "date                                                                   \n",
       "2002-02-28                    2986.310                       7954.130  \n",
       "2002-03-31                    3014.280                       7983.170  \n",
       "2002-04-30                    3042.260                       8012.210  \n",
       "2002-05-31                    3070.240                       8041.250  \n",
       "2002-06-30                    3098.220                       8070.290  \n",
       "...                                ...                            ...  \n",
       "2021-08-31                    7325.470                      18174.560  \n",
       "2021-09-30                    7328.510                      18207.820  \n",
       "2021-10-31                    7331.560                      18241.070  \n",
       "2021-11-30                    7334.600                      18274.330  \n",
       "2021-12-31                    7337.650                      18307.580  \n",
       "\n",
       "[234 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOÇÃO DE CAMPOS NAN\n",
    "df = df_full[features].copy()\n",
    "print(df.shape)\n",
    "df = df[df['sunflower_production'].notnull()]\n",
    "df = df[df['sunflower_price'].notnull()]\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "ZjAfeXKzEp8n",
    "outputId": "cf8cffd0-ba60-4ad1-d04e-8bdac73c9fef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coconut_exports</th>\n",
       "      <th>coconut_price</th>\n",
       "      <th>coconut_production</th>\n",
       "      <th>palm-kernel_exports</th>\n",
       "      <th>palm-kernel_price</th>\n",
       "      <th>palm-kernel_production</th>\n",
       "      <th>palm_exports</th>\n",
       "      <th>palm_price</th>\n",
       "      <th>palm_production</th>\n",
       "      <th>peanut_exports</th>\n",
       "      <th>...</th>\n",
       "      <th>soybean_price</th>\n",
       "      <th>soybean_production</th>\n",
       "      <th>sunflower_exports</th>\n",
       "      <th>sunflower_price</th>\n",
       "      <th>sunflower_production</th>\n",
       "      <th>vegetable-oil_exports</th>\n",
       "      <th>vegetable-oil_price</th>\n",
       "      <th>vegetable-oil_production</th>\n",
       "      <th>vegetable-oil_oecd_exports</th>\n",
       "      <th>vegetable-oil_oecd_production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>...</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>234.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.793</td>\n",
       "      <td>1037.208</td>\n",
       "      <td>277.760</td>\n",
       "      <td>233.840</td>\n",
       "      <td>956.092</td>\n",
       "      <td>523.365</td>\n",
       "      <td>3226.635</td>\n",
       "      <td>763.075</td>\n",
       "      <td>4406.418</td>\n",
       "      <td>19.901</td>\n",
       "      <td>...</td>\n",
       "      <td>882.535</td>\n",
       "      <td>4857.446</td>\n",
       "      <td>563.021</td>\n",
       "      <td>966.043</td>\n",
       "      <td>1174.819</td>\n",
       "      <td>5990.575</td>\n",
       "      <td>103.046</td>\n",
       "      <td>14277.728</td>\n",
       "      <td>5545.769</td>\n",
       "      <td>13471.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.334</td>\n",
       "      <td>412.612</td>\n",
       "      <td>12.313</td>\n",
       "      <td>41.691</td>\n",
       "      <td>378.930</td>\n",
       "      <td>139.269</td>\n",
       "      <td>805.918</td>\n",
       "      <td>244.906</td>\n",
       "      <td>1262.844</td>\n",
       "      <td>6.470</td>\n",
       "      <td>...</td>\n",
       "      <td>272.357</td>\n",
       "      <td>980.073</td>\n",
       "      <td>284.888</td>\n",
       "      <td>334.951</td>\n",
       "      <td>331.668</td>\n",
       "      <td>1329.965</td>\n",
       "      <td>32.741</td>\n",
       "      <td>3166.837</td>\n",
       "      <td>1307.176</td>\n",
       "      <td>3118.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>123.000</td>\n",
       "      <td>366.000</td>\n",
       "      <td>248.500</td>\n",
       "      <td>130.470</td>\n",
       "      <td>353.240</td>\n",
       "      <td>264.710</td>\n",
       "      <td>1527.920</td>\n",
       "      <td>352.980</td>\n",
       "      <td>2146.310</td>\n",
       "      <td>12.830</td>\n",
       "      <td>...</td>\n",
       "      <td>359.210</td>\n",
       "      <td>3204.320</td>\n",
       "      <td>166.180</td>\n",
       "      <td>543.000</td>\n",
       "      <td>620.920</td>\n",
       "      <td>3312.180</td>\n",
       "      <td>47.622</td>\n",
       "      <td>8559.630</td>\n",
       "      <td>2986.310</td>\n",
       "      <td>7954.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>148.055</td>\n",
       "      <td>702.250</td>\n",
       "      <td>270.998</td>\n",
       "      <td>219.213</td>\n",
       "      <td>655.290</td>\n",
       "      <td>399.255</td>\n",
       "      <td>2515.020</td>\n",
       "      <td>577.495</td>\n",
       "      <td>3275.315</td>\n",
       "      <td>15.468</td>\n",
       "      <td>...</td>\n",
       "      <td>719.372</td>\n",
       "      <td>4057.825</td>\n",
       "      <td>329.412</td>\n",
       "      <td>719.643</td>\n",
       "      <td>886.732</td>\n",
       "      <td>5027.562</td>\n",
       "      <td>78.436</td>\n",
       "      <td>11538.903</td>\n",
       "      <td>4463.065</td>\n",
       "      <td>10815.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>154.895</td>\n",
       "      <td>953.500</td>\n",
       "      <td>275.410</td>\n",
       "      <td>245.990</td>\n",
       "      <td>878.330</td>\n",
       "      <td>530.115</td>\n",
       "      <td>3399.860</td>\n",
       "      <td>732.000</td>\n",
       "      <td>4468.605</td>\n",
       "      <td>16.805</td>\n",
       "      <td>...</td>\n",
       "      <td>832.990</td>\n",
       "      <td>4667.785</td>\n",
       "      <td>493.780</td>\n",
       "      <td>856.470</td>\n",
       "      <td>1127.385</td>\n",
       "      <td>5927.510</td>\n",
       "      <td>97.910</td>\n",
       "      <td>14325.960</td>\n",
       "      <td>5663.720</td>\n",
       "      <td>13418.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>160.400</td>\n",
       "      <td>1387.287</td>\n",
       "      <td>287.767</td>\n",
       "      <td>263.450</td>\n",
       "      <td>1232.705</td>\n",
       "      <td>642.967</td>\n",
       "      <td>4014.682</td>\n",
       "      <td>886.188</td>\n",
       "      <td>5503.118</td>\n",
       "      <td>23.133</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.713</td>\n",
       "      <td>5831.602</td>\n",
       "      <td>867.900</td>\n",
       "      <td>1174.505</td>\n",
       "      <td>1528.378</td>\n",
       "      <td>7278.573</td>\n",
       "      <td>121.403</td>\n",
       "      <td>17158.577</td>\n",
       "      <td>6772.868</td>\n",
       "      <td>16394.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>177.920</td>\n",
       "      <td>2256.000</td>\n",
       "      <td>302.500</td>\n",
       "      <td>283.170</td>\n",
       "      <td>2307.630</td>\n",
       "      <td>725.000</td>\n",
       "      <td>4325.500</td>\n",
       "      <td>1377.220</td>\n",
       "      <td>6299.500</td>\n",
       "      <td>40.580</td>\n",
       "      <td>...</td>\n",
       "      <td>1574.670</td>\n",
       "      <td>6381.500</td>\n",
       "      <td>1122.670</td>\n",
       "      <td>2045.000</td>\n",
       "      <td>1761.580</td>\n",
       "      <td>7887.340</td>\n",
       "      <td>184.837</td>\n",
       "      <td>19012.500</td>\n",
       "      <td>7349.260</td>\n",
       "      <td>18307.580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       coconut_exports  coconut_price  coconut_production  \\\n",
       "count          234.000        234.000             234.000   \n",
       "mean           154.793       1037.208             277.760   \n",
       "std             10.334        412.612              12.313   \n",
       "min            123.000        366.000             248.500   \n",
       "25%            148.055        702.250             270.998   \n",
       "50%            154.895        953.500             275.410   \n",
       "75%            160.400       1387.287             287.767   \n",
       "max            177.920       2256.000             302.500   \n",
       "\n",
       "       palm-kernel_exports  palm-kernel_price  palm-kernel_production  \\\n",
       "count              234.000            234.000                 234.000   \n",
       "mean               233.840            956.092                 523.365   \n",
       "std                 41.691            378.930                 139.269   \n",
       "min                130.470            353.240                 264.710   \n",
       "25%                219.213            655.290                 399.255   \n",
       "50%                245.990            878.330                 530.115   \n",
       "75%                263.450           1232.705                 642.967   \n",
       "max                283.170           2307.630                 725.000   \n",
       "\n",
       "       palm_exports  palm_price  palm_production  peanut_exports  ...  \\\n",
       "count       234.000     234.000          234.000         234.000  ...   \n",
       "mean       3226.635     763.075         4406.418          19.901  ...   \n",
       "std         805.918     244.906         1262.844           6.470  ...   \n",
       "min        1527.920     352.980         2146.310          12.830  ...   \n",
       "25%        2515.020     577.495         3275.315          15.468  ...   \n",
       "50%        3399.860     732.000         4468.605          16.805  ...   \n",
       "75%        4014.682     886.188         5503.118          23.133  ...   \n",
       "max        4325.500    1377.220         6299.500          40.580  ...   \n",
       "\n",
       "       soybean_price  soybean_production  sunflower_exports  sunflower_price  \\\n",
       "count        234.000             234.000            234.000          234.000   \n",
       "mean         882.535            4857.446            563.021          966.043   \n",
       "std          272.357             980.073            284.888          334.951   \n",
       "min          359.210            3204.320            166.180          543.000   \n",
       "25%          719.372            4057.825            329.412          719.643   \n",
       "50%          832.990            4667.785            493.780          856.470   \n",
       "75%         1016.713            5831.602            867.900         1174.505   \n",
       "max         1574.670            6381.500           1122.670         2045.000   \n",
       "\n",
       "       sunflower_production  vegetable-oil_exports  vegetable-oil_price  \\\n",
       "count               234.000                234.000              234.000   \n",
       "mean               1174.819               5990.575              103.046   \n",
       "std                 331.668               1329.965               32.741   \n",
       "min                 620.920               3312.180               47.622   \n",
       "25%                 886.732               5027.562               78.436   \n",
       "50%                1127.385               5927.510               97.910   \n",
       "75%                1528.378               7278.573              121.403   \n",
       "max                1761.580               7887.340              184.837   \n",
       "\n",
       "       vegetable-oil_production  vegetable-oil_oecd_exports  \\\n",
       "count                   234.000                     234.000   \n",
       "mean                  14277.728                    5545.769   \n",
       "std                    3166.837                    1307.176   \n",
       "min                    8559.630                    2986.310   \n",
       "25%                   11538.903                    4463.065   \n",
       "50%                   14325.960                    5663.720   \n",
       "75%                   17158.577                    6772.868   \n",
       "max                   19012.500                    7349.260   \n",
       "\n",
       "       vegetable-oil_oecd_production  \n",
       "count                        234.000  \n",
       "mean                       13471.372  \n",
       "std                         3118.232  \n",
       "min                         7954.130  \n",
       "25%                        10815.903  \n",
       "50%                        13418.630  \n",
       "75%                        16394.708  \n",
       "max                        18307.580  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2R_Zrs4dMtP2"
   },
   "source": [
    "## Correlação\n",
    "\n",
    "Paired density and scatterplot matrix\n",
    "\n",
    "https://seaborn.pydata.org/examples/pair_grid_with_kde.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zGGVt6M-MsoV"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    %time\n",
    "    sns.set_theme(style=\"white\")\n",
    "\n",
    "    g = sns.PairGrid(df, diag_sharey=False)\n",
    "    g.map_upper(sns.scatterplot, s=15)\n",
    "    g.map_lower(sns.kdeplot)\n",
    "    g.map_diag(sns.kdeplot, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9WbkR3OLOiD"
   },
   "source": [
    "![Alt text](https://raw.githubusercontent.com/fkfouri/vegetable_oil_mkt/master/images/Compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7h70OHMMsXn"
   },
   "source": [
    "## Dendograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1Qp4dW-kNGmt"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plt.figure(figsize=(25,10))\n",
    "    dendrogram = sch.dendrogram(sch.linkage(df, method  = \"ward\"))\n",
    "\n",
    "    plt.title('Dendrogram')\n",
    "\n",
    "    # plt.xlabel('Customers')\n",
    "    plt.ylabel('Euclidean distances')\n",
    "    %time plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJUSeS-rQHm3"
   },
   "source": [
    "# Markov\n",
    "Observaçoes:\n",
    "- Sera que o outcome deveria ser calculado em funcao do dado? Não deveria ser uma referencia Exogena? Exemplos (Open Interest da soja eu tenho). No exemplo do VIRAL... ele pega o outcome como o volume de negocios.\n",
    "- O que fazer com os preditores dentro do random_set (??)\n",
    "\n",
    "Tentativa de segregar os patterns em, para ter padroes menores:\n",
    "- product_variation\n",
    "- exports_variation\n",
    "- price_variation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPuC2yQVU1uj",
    "outputId": "c7005dbd-a73d-4df8-deb5-289c64e22062"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade quantecon numba tqdm --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_divison  = lambda size: [item / size for item in list(range(size + 1))]\n",
    "get_labels   = lambda size, start=0: [f'{chr( (item % 26 + start) + 65  )}{ \"\" if item // 26 <= 0 else item // 26 }' for item in list(range(size))]\n",
    "get_full     = lambda size: [ (chr(i + 65), f'{j / size} < x <= { (j+1) / size}' ) for i , j in enumerate(range(size))]\n",
    "get_bins     = lambda _input_array, size:  np.round(np.linspace(_input_array.min(), _input_array.max(), size + 1), 6).tolist()\n",
    "\n",
    "\n",
    "def read_kwarg_list(kwargs, name, _else_conditions = None):\n",
    "    if name in kwargs and isinstance(kwargs[name], list):\n",
    "        return kwargs[name]\n",
    "    return _else_conditions\n",
    "\n",
    "def read_kwarg_bool(kwargs, name):\n",
    "    if name in kwargs and isinstance(kwargs[name], Boolean):\n",
    "        return kwargs[name]\n",
    "    return False\n",
    "        \n",
    "    \n",
    "def reset_logging():\n",
    "    \"\"\"\n",
    "    Reset logging - Tira as definicoes de DEBUG, INFO, etc\n",
    "    \"\"\"\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convet_collection_to_dataframe(collection):\n",
    "    \"\"\"\n",
    "    Concatena todas as colecoes\n",
    "    Remove os np.inf e np.nan, gerados pelo pc_change\n",
    "    \"\"\"\n",
    "    df_out = pd.concat(collection)\n",
    "    \n",
    "    log.debug(f'Before dropping NaNs: {df_out.shape}')\n",
    "    df_out.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_out = df_out.dropna(how='any') \n",
    "    log.debug(f'After dropping NaNs: {df_out.shape}')\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRI24xw0lj2E"
   },
   "source": [
    "## Geração do Random Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.DEBUG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GZX99tD0RPmz"
   },
   "outputs": [],
   "source": [
    "#Gera uma serie de forma randomica. Pega amostras do dataset com horizonte de 3 a 18 linhas (meses) e \n",
    "def get_random_sets(input_dataframe: pd.DataFrame, \n",
    "                    size = 100000,\n",
    "                    **kwargs):\n",
    "    \n",
    "    # take random sets of sequential rows \n",
    "    new_set = []\n",
    "\n",
    "    # breakpoint()\n",
    "    \n",
    "    log.debug(f'AQUI:   {size}')\n",
    "    for row_set in (tqdm(iterable = range(0, size), bar_format='{desc:<15}{percentage:3.0f}%|{bar:50}{r_bar}' ) ):\n",
    "        \n",
    "        # obtem de forma randomica uma amostra de n linhas do dataset entre 3 e 18 meses\n",
    "        row_quant     = randint(3, 18)\n",
    "        row_start     = randint(0, len(input_dataframe) - row_quant)\n",
    "        row_finish    = row_start + row_quant\n",
    "\n",
    "        market_subset = input_dataframe.iloc[row_start:row_finish]\n",
    "        Close_Date    = max(market_subset['date'])\n",
    "        \n",
    "        log.debug(f'AQUI:   {row_start} |{row_finish} | {market_subset.shape} | {Close_Date}')\n",
    "\n",
    "        if row_set%(size//5)==0:\n",
    "            pass\n",
    "            print(f'row_set: {row_set:<6} | row_quant: {row_quant:2} | rows: {row_start:>6}-{row_finish-1:<6} | market_subset: {str(market_subset.shape):^10} | Close_Date: {Close_Date:%m/%d/%Y}')\n",
    "               \n",
    "        ref = {}\n",
    "        ref['Sequence_ID']  = [row_set] * row_quant\n",
    "        ref['Close_Date']   = [Close_Date] * row_quant\n",
    "        ref['ref_date']     = market_subset['date']\n",
    "        ref['size_dataset'] = [len(market_subset) - 2] * row_quant  # subtracao de dois devido limpeza NaN\n",
    "        \n",
    "#         # TODO: Leitura dos Preditores, Tipo Media do período  \n",
    "#         # parece ser irrelevante... pois houve uma interpolcao durante upstream. \n",
    "#         # A Media tente a ser a mesma para datasets dentro de um mesmo ano\n",
    "#         for name, value in market_subset[PREDITOR].iteritems():\n",
    "#             ref[f'{name}_mean']       = value.mean() \n",
    "        \n",
    "\n",
    "        # Colunas que NAO desejo realizar a variacao\n",
    "        bypass_ref = {}\n",
    "        \n",
    "        if 'bypass' in kwargs and isinstance(kwargs['bypass'], list):\n",
    "            for _col in kwargs['bypass']:\n",
    "                bypass_ref[_col] = market_subset[_col]\n",
    "                \n",
    "                       \n",
    "        # columnas que desejo ter as variacoes em relacao a linha anterior (date)\n",
    "        columns_ref = {}\n",
    "        if 'columns' in kwargs and isinstance(kwargs['columns'], list):\n",
    "            for _col in kwargs['columns']:\n",
    "                if _col in input_dataframe.columns and _col not in bypass_ref:\n",
    "                    columns_ref[_col] = market_subset[_col]\n",
    "                    columns_ref[f'{_col}_variation'] = market_subset[_col].pct_change()\n",
    "                    \n",
    "                    if 'outcomes' in kwargs and isinstance(kwargs['outcomes'], list) and _col in kwargs['outcomes']:\n",
    "                        columns_ref[f'{_col}_outcome'] = market_subset[_col].diff(-1) * -1\n",
    "        \n",
    "\n",
    "               \n",
    "        #merge dictionaries\n",
    "        ref = {**ref, **bypass_ref, **columns_ref}\n",
    "        \n",
    "        new_set.append(pd.DataFrame(ref))\n",
    "        \n",
    "    return new_set\n",
    "\n",
    "# get_random_sets(df.reset_index(), RANDOM_SIZE, columns=features,  outcomes=features, bypass=PREDITOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWdHQv5JSITJ",
    "outputId": "05e724fc-8732-42a1-c322-5507a4986d15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 0%|                                                  | 10/10000 [00:00<03:49, 43.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_set: 0      | row_quant:  5 | rows:      7-11     | market_subset:  (5, 27)   | Close_Date: 06/30/2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                20%|██████████                                        | 2009/10000 [00:30<01:57, 67.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_set: 2000   | row_quant: 18 | rows:    103-120    | market_subset:  (18, 27)  | Close_Date: 07/31/2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                39%|███████████████████▎                              | 3852/10000 [00:59<01:35, 64.19it/s]"
     ]
    }
   ],
   "source": [
    "%time my_set_case2 = get_random_sets(df.reset_index(), RANDOM_SIZE, columns=features,  outcomes=features, bypass=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "zpn4a7ZOkT0x",
    "outputId": "b98168f0-bf29-4f37-f6f8-6aad21f0cb65"
   },
   "outputs": [],
   "source": [
    "%time df1 = convet_collection_to_dataframe(my_set_case2)\n",
    "print(df1.shape)\n",
    "# df1.sort_values(by=['ref_date'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[PREDITOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DByw2R9sAiGk",
    "outputId": "40fc3fa6-b661-4185-b96a-60f12779979a"
   },
   "outputs": [],
   "source": [
    "#Lista de features tipo outcome\n",
    "outcomes = [x for x in df1.columns if 'outcome' in x  ]\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83c71ABWl6QD"
   },
   "source": [
    "## Divisao em Quantis\n",
    "\n",
    "Processo de Discretização em **n** quantis. Processo de simplificação dos dados categorizados e criacao de grupos.\n",
    "\n",
    "Significa que para uma data qualquer... os possiveis acontecimentos predecessores *(LHM, MLH, etc)* que o fizeram chegar a aquele resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMdeeDslmZ3J"
   },
   "outputs": [],
   "source": [
    "def quantiles_v2(df: pd.DataFrame, size = 3):\n",
    "    df    = df.copy()\n",
    "\n",
    "    columns_production  = []\n",
    "    columns_exports     = []\n",
    "    columns_prices      = []\n",
    "    columns_veg         = []\n",
    "    \n",
    "    for i, col in enumerate(df.columns):\n",
    "        column_name         = f'{col}_qcut'\n",
    "        \n",
    "        # EXecuta o qcut em campos que tem no nome a referencia 'variation' mas que nao seja tipo 'vegetable'\n",
    "        if 'variation' in col and 'vegetable' not in col:\n",
    "        \n",
    "            if 'exports' in col:\n",
    "                labels = get_labels(size, 0*size)\n",
    "                df[column_name]     = pd.qcut(df[col], q=size, labels = labels)\n",
    "                columns_exports.append(column_name)    \n",
    "                \n",
    "            elif 'price' in col:\n",
    "                labels = get_labels(size, 2*size)\n",
    "                df[column_name]     = pd.qcut(df[col], q=size, labels = labels)\n",
    "                columns_prices.append(column_name) \n",
    "                \n",
    "            elif 'production' in col:\n",
    "                labels = get_labels(size, 4*size)\n",
    "\n",
    "                df[column_name]     = pd.qcut(df[col], q=size, labels = labels)\n",
    "                columns_production.append(column_name)\n",
    "\n",
    "  \n",
    "        \n",
    "        elif 'variation' in col and 'vegetable' in col:\n",
    "            labels = get_labels(size, 6*size)\n",
    "            df[column_name]     = pd.qcut(df[col], q=size, labels = labels)\n",
    "            columns_veg.append(column_name) \n",
    "            \n",
    "            \n",
    "            \n",
    "    def get_equation(columns):\n",
    "        return ' + '.join( [f'df[\"{col}\"].astype(str)' for col in columns] )\n",
    "        \n",
    "    df['event_pattern_production']  = eval(get_equation(columns_production)) \n",
    "    df['event_pattern_exports']     = eval(get_equation(columns_exports)) \n",
    "    df['event_pattern_prices']      = eval(get_equation(columns_prices)) \n",
    "    df['veg_pattern']               = eval(get_equation(columns_veg)) \n",
    "    total_patterns = 4\n",
    "    \n",
    "    outcomes = [x for x in df1.columns if 'outcome' in x  ]\n",
    "    \n",
    "    columns_fixed   = list(df.columns[:4])\n",
    "    columns_sort    = sorted(list(df.columns[4:-total_patterns]))\n",
    "#     columns_sort    = sorted(columns_production + columns_exports + columns_prices + outcomes)\n",
    "    columns_event   = sorted(list(df.columns[-total_patterns:]))\n",
    "    \n",
    "\n",
    "    return df[columns_fixed + columns_event + columns_sort].sort_values(by = ['Close_Date', 'Sequence_ID'], ascending=[False, True])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "gfzQCEFhnn1J",
    "outputId": "fb922590-5f53-47d0-b07f-1584401fa564"
   },
   "outputs": [],
   "source": [
    "df2 = quantiles_v2(df1, size=QTD_BINS)\n",
    "print(df2.shape)\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[PREDITOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b_8E7B2sZ43"
   },
   "source": [
    "## Compressing*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unifica os *patterns* em uma coluna. \n",
    "\n",
    "A saida tem um shape que retorna ao tamanho tamanho do **RANDOM_SIZE**.\n",
    "\n",
    "NAO é mais necessario a referencia de Date. O interesse eh somente pelos padroes.\n",
    "\n",
    "Verificar:\n",
    "- Se deve ou nao usar o SET. O importante é identificar as transições de estados anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ViVdZJUrwSB"
   },
   "outputs": [],
   "source": [
    "def compress_v1(df: pd.DataFrame, **kwargs):\n",
    "    \"\"\"\n",
    "    Nao eh aplicado o set. Consegue-se observar as transicoes de estados que anteciparam o estado corrente. \n",
    "    Pode ter repeticao. Acho mais importante! \n",
    "    \"\"\"\n",
    "    columns         = read_kwarg_list(kwargs,'columns')\n",
    "    outcomes        = read_kwarg_list(kwargs,'outcomes')\n",
    "    predictors      = read_kwarg_list(kwargs,'predictors')\n",
    "    event_patterns  = [x for x in df.columns if 'event_pattern' in x  ]\n",
    "    \n",
    "    #Agrupa os event_pattern unicos em uma unica coluna\n",
    "    if columns and len(event_patterns) >= 1:\n",
    "        # Nao podia usar o set... pois precisava da repeticao para compararcao entre fors\n",
    "        # da funcao build_transition_grid_v2\n",
    "        df_step1 = df.groupby(columns)[event_patterns].\\\n",
    "                    agg(lambda x: ','.join( list( x ) ) )\n",
    "\n",
    "    #Agrupa os veg_pattern somente em uma unica coluna\n",
    "    veg_pattern = [x for x in df.columns if 'veg_pattern' in x  ]   \n",
    "    if columns and len(veg_pattern) >= 1:\n",
    "        df_step1a = df.groupby(columns)[veg_pattern].\\\n",
    "                    agg(lambda x: ','.join( list(  x ) ) )\n",
    "        \n",
    "        df_step1 = pd.merge(df_step1, df_step1a, on=columns, how='inner')\n",
    "        \n",
    "\n",
    "    if predictors and len(predictors) >= 1:\n",
    "        df_step1b = df.groupby(columns)[predictors].mean()\n",
    "        \n",
    "        df_step1 = pd.merge(df_step1, df_step1b, on=columns, how='inner')        \n",
    "        \n",
    "\n",
    "    #Agrupa os valores dos outcomes pela media\n",
    "    if columns and outcomes:\n",
    "        df_step2 = df.groupby(columns)[outcomes].mean()\n",
    "        \n",
    "    compressed_set = pd.merge(df_step1, df_step2, on=columns, how='inner')\n",
    "    \n",
    "    return compressed_set\n",
    "    \n",
    "    agrupador      = 'events_pattern'\n",
    "    \n",
    "#     compressed_set[agrupador] = compressed_set[event_patterns].agg(','.join, axis=1)\n",
    "       \n",
    "    # Usando funcao de conjuntos para escolher as colunas da saida. A lista delta nao contem os agregadores tipo event_patterns\n",
    "    array1  = np.array(list(compressed_set.columns))\n",
    "    array2  = np.array([agrupador]) # np.array(event_patterns + [agrupador])\n",
    "    delta   = np.setdiff1d(array1, array2, assume_unique=True)\n",
    "\n",
    "    return compressed_set[ [event_patterns] + list(delta)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "dqadY3nE3hyZ",
    "outputId": "634a9e74-14da-4e71-a477-f13f6087eb14"
   },
   "outputs": [],
   "source": [
    "df3 = compress_v1(df2, columns = ['Sequence_ID', 'Close_Date'],  outcomes = outcomes)\n",
    "print(df3.shape)\n",
    "df3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4wIDIrW94zY",
    "outputId": "3173f776-ed7e-4673-a9f0-57860e716422"
   },
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IizMHtO9ISz"
   },
   "source": [
    "## Simplificando o Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo aqui é remover variacoes de pouca relevancia.\n",
    "\n",
    "Exemplo: \n",
    "- A flutuação de + ou - 10 centavos de dolar pode não ser representativo em um dataset de preço da tonela oleo de soja ... que opera na casa de milhares de dolares. Mas 10 centavos é representativo para o cambio dolar/real, que opera na casa  5 BRL ~ 1 USD.\n",
    "- Pode ser até erro de precisão. 1000 kg ou 999 kg é a mesma coisa em termos de ordem de grandeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "dvTApRET9_4o",
    "outputId": "106f7e22-7a96-4631-e2be-5a7c4a4492a4"
   },
   "outputs": [],
   "source": [
    "df3[[x for x in df3.columns if 'vegetable' in x  ]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7ojcr3q5UQ4",
    "outputId": "145a3729-643d-4b79-9580-4576adacc19f"
   },
   "outputs": [],
   "source": [
    "relevant_cut_off  = .5 #variacao maior que .5 pontos \n",
    "outcome_reference = 'vegetable-oil_price_outcome'\n",
    "\n",
    "print(f'All available data: { df3.shape[0]}')\n",
    "df4 = df3[ abs(df3[outcome_reference]) > relevant_cut_off ][:]\n",
    "print(f'Relevant changes: { df4.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "K7w1pJLP90VS",
    "outputId": "cc65c3ac-6585-43cc-a910-1dad3a125cf9"
   },
   "outputs": [],
   "source": [
    "df4[[x for x in df4.columns if 'vegetable' in x]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYD0KHxBDtkr"
   },
   "source": [
    "## Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste ponto, o objetivo é criar um flag 0/1 (False/True) para informar se a sequencia de transição direcionar para crescimento (bulish) ou para caida (bearish).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directions(df: pd.DataFrame):\n",
    "    df    = df.copy()\n",
    "\n",
    "    for col in [x for x in df.columns if 'outcome' in x ]:\n",
    "        column_name         = f'{col}_direction'\n",
    "        df[column_name]     = df[col].apply(lambda x: 1 if x > 0 else 0 )\n",
    "\n",
    "    # quantidade de colunas sem outcome na descricao\n",
    "    qtd_cols = len([x for x in df.columns if 'outcome' not in x])\n",
    "        \n",
    "    columns_fixed   = list(df.columns[:qtd_cols])\n",
    "    columns_sort    = sorted(list(df.columns[qtd_cols:]))\n",
    "    \n",
    "#     return df[columns_fixed + columns_sort].sort_values(by = ['Sequence_ID'], ascending=[True]) \\\n",
    "#             .reset_index().set_index(['Sequence_ID', 'Close_Date'])\n",
    "\n",
    "    return df[columns_fixed + columns_sort].sort_values(by = ['Close_Date'], ascending=[True]) \\\n",
    "            .reset_index().set_index(['Sequence_ID', 'Close_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "KY9UneKaESLV",
    "outputId": "662a6271-f174-468a-cca9-3091cb9e588e"
   },
   "outputs": [],
   "source": [
    "#sem simplificacao\n",
    "%time df5 = directions(df4)\n",
    "print(df5.shape)\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btHM7U56CLd-"
   },
   "source": [
    "## Split Train/Test\n",
    "\n",
    "O Shuffle esta desativado. Não sera realizado embaralhamento de serie temporal, para evitar o erro de prever o passado com dados do futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBI_GFCMGJLt",
    "outputId": "099ebee6-9f02-4cc6-b6dd-0c251c06d0cb"
   },
   "outputs": [],
   "source": [
    "event_patterns = [x for x in df5.columns if 'event_pattern' in x  ]\n",
    "print(event_patterns)\n",
    "\n",
    "feature_directions = event_patterns + [x for x in df5.columns if 'direction' in x and 'vegetable-oil' not in x ]\n",
    "print(feature_directions)\n",
    "\n",
    "predictors = [x for x in df5.columns if 'direction' in x and 'vegetable-oil' in x and 'oecd' not in x ]\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDty_RDA_Zjo"
   },
   "outputs": [],
   "source": [
    "X = df5[feature_directions]\n",
    "y = df5[predictors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQHX86S6Gq25",
    "outputId": "edb44724-23bc-4ec1-8199-7b00fcb0bba6"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=False)\n",
    "print(f'X_train: {X_train.shape} | X_test: {X_test.shape} | y_train: {y_train.shape} | y_test: {y_test.shape} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "NYfuPIFzHDRp",
    "outputId": "3f5c96fa-1d93-435a-e805-473a6c48c945"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.sort_values(by=['Sequence_ID'])\n",
    "X_train.sort_values(by=['Close_Date'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.sort_values(by=['Sequence_ID'])\n",
    "X_test.sort_values(by=['Close_Date'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df5.columns if 'direction' in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IKyMFLUHHtR",
    "outputId": "bb4ebd12-0a52-42f2-a4ee-42adf582c76a"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, \"Metade de linhas:\", X_train.shape[0]/2)\n",
    "print('=='*60)\n",
    "print('Vou usar a referencia de \"sunflower_production_outcome_direction\" por ser o fator determinando pertubador de mercado. ')\n",
    "print('=='*60)\n",
    "\n",
    "X_train[[x for x in X_train.columns if 'direction' in x ]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullish/Bearish Cenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfIDFy58NFGv",
    "outputId": "e056ebb6-d616-4674-f97e-249bb25f5e58"
   },
   "outputs": [],
   "source": [
    "direction_reference = 'sunflower_production_outcome_direction'\n",
    "df6_pos = X_train.loc[X_train[direction_reference] > 0]\n",
    "df6_neg = X_train.loc[X_train[direction_reference] <= 0]\n",
    "print(f'df6_pos: {df6_pos.shape} | df6_neg: {df6_neg.shape}')\n",
    "df6_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgxzw4WqOrqA"
   },
   "outputs": [],
   "source": [
    "def get_unique_patterns_V1(input_array: np.ndarray, **kwargs):\n",
    "    \"\"\" \n",
    "    Aqui o 'get_labels' nao deve fazer parte... pois os unique patterns pode estar agrupado. Ex. AAA, ABC, etc\n",
    "    \"\"\"\n",
    "    flat_list = [ item.split(',') for item in input_array ]\n",
    "    unique_patterns = ','.join(str(r) for v in flat_list for r in v)\n",
    "    unique_patterns = sorted(list( set( unique_patterns.split(',') ) ))\n",
    "    return unique_patterns\n",
    "\n",
    "def get_unique_patterns_V2(input_array: np.ndarray, **kwargs):\n",
    "    \"\"\" \n",
    "    Aqui o 'get_labels' nao deve fazer parte... pois os unique patterns pode estar agrupado. Ex. AAA, ABC, etc\n",
    "    \"\"\"\n",
    "    unique_patterns = []\n",
    "    for i in range(len(input_array[0])):\n",
    "\n",
    "        flat_list = [ item[i].split(',') for item in input_array ]\n",
    "        temp_patterns = ','.join(str(r) for v in flat_list for r in v)\n",
    "        unique_patterns += temp_patterns.split(',')\n",
    "                \n",
    "    unique_patterns = sorted(list( set(unique_patterns ) ))\n",
    "    return unique_patterns\n",
    "\n",
    "\n",
    "def get_unique_patterns_V3(input_array: np.ndarray, **kwargs):\n",
    "    \"\"\" \n",
    "    Aqui o 'get_labels' nao deve fazer parte... pois os unique patterns pode estar agrupado. Ex. AAA, ABC, etc\n",
    "    \"\"\"\n",
    "    unique_patterns = {}\n",
    "    for i in range(len(input_array[0])):\n",
    "\n",
    "        flat_list = [ item[i].split(',') for item in input_array ]\n",
    "        temp_patterns = ','.join(str(r) for v in flat_list for r in v)\n",
    "        unique_patterns[i] += temp_patterns.split(',')\n",
    "                \n",
    "#     unique_patterns = sorted(list( set(unique_patterns ) ))\n",
    "    return unique_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X_train[event_patterns].values[1][0].split(\",\")[0].split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_list = [ item[0].split(',') for item in X_train[event_patterns].values ]\n",
    "# flat_list = [ j[0].split('-') for j in   [i[0].split(\",\") for i in X_train[event_patterns].values]] \n",
    "# flat_list\n",
    "# # unique_patterns = ','.join(str(r) for v in flat_list for r in v)\n",
    "# # unique_patterns = sorted(list( set( unique_patterns.split(',') ) ))\n",
    "# unique_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAn3xV6zOwXo",
    "outputId": "d5e1b67f-903e-4cd8-8163-a98e90793be6"
   },
   "outputs": [],
   "source": [
    "unique_patterns_exports = get_unique_patterns_V1(X_train['event_pattern_exports'].values)\n",
    "print(len(unique_patterns_exports), unique_patterns_exports[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patterns_prices = get_unique_patterns_V1(X_train['event_pattern_prices'].values)\n",
    "print(len(unique_patterns_prices), unique_patterns_prices[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patterns_production = get_unique_patterns_V1(X_train['event_pattern_production'].values)\n",
    "print(len(unique_patterns_production), unique_patterns_production[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnU_uwMOMqJQ"
   },
   "source": [
    "## Matriz de Markov\n",
    "\n",
    "Matriz estocastica\n",
    "- cada elemento da matriz é positivo\n",
    "- a somatoria de cada linha é 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_grid_markov(patterns, counts, counts_fk):\n",
    "\n",
    "#     log.debug(f'patterns: {patterns}')\n",
    "#     log.debug(f'counts: {counts}')\n",
    "#     log.debug(f'counts_fk: {counts_fk}')\n",
    "\n",
    "    # create to/from grid\n",
    "    grid_markov = pd.DataFrame({'pairs':patterns, 'counts': counts})\n",
    "    log.debug(f'CRIACAO GRID: {grid_markov.shape} | {grid_markov}')\n",
    "    \n",
    "    # group by, para remover as duplicacoes de multiplos patterns\n",
    "    grid_markov = grid_markov.groupby(['pairs'])['counts'].sum().to_frame().reset_index()\n",
    "    log.debug(f'GRID GROUPED: {grid_markov.shape} | {grid_markov}')\n",
    "\n",
    "    # quebra em x,y a coluna combinada\n",
    "    grid_markov[['x', 'y']] = grid_markov['pairs'].str.split(',', n=1, expand=True)\n",
    "    log.debug(f'GRID X,Y: {grid_markov.shape} | {grid_markov}')\n",
    "\n",
    "    # pivoteamento em x e y\n",
    "    grid_markov = grid_markov.pivot(index='x', columns='y', values='counts')\n",
    "    log.debug(f'GRID PIVOT: {grid_markov.shape} | {grid_markov}')\n",
    "    \n",
    "    # Renomeia as colunas. Remove a referencia 'y'\n",
    "    grid_markov.columns= [col for col in grid_markov.columns]\n",
    "    log.debug(f'GRID RENAME COLUMNS: {grid_markov}')\n",
    "       \n",
    "    # replace all NaN with zeros\n",
    "    grid_markov.fillna(0, inplace=True)\n",
    "    log.debug(f'GRID FILLNA: {grid_markov}')\n",
    "    \n",
    "    # cria uma coluna temporaria para a soma da linha\n",
    "    grid_markov['soma'] = grid_markov.sum(axis=1)\n",
    "    log.debug(f'GRID SOMA: {grid_markov.shape} | {grid_markov}')\n",
    "\n",
    "    # grid_markov.rowSums(transition_dataframe) \n",
    "    # grid_markov = grid_markov / grid_markov['soma']\n",
    "    \n",
    "    # calcula o percentual de cada valor sobre a soma    \n",
    "    for col in grid_markov.columns:\n",
    "        grid_markov[col] = grid_markov[col] / grid_markov['soma'] \n",
    "        grid_markov.fillna(0, inplace=True)\n",
    "    log.debug(f'GRID PERCENT: {grid_markov.shape} | {grid_markov}')\n",
    "    \n",
    "    ## Correcao onde soma eh zero\n",
    "    # for i, row in grid_markov[grid_markov['soma'] == 0].iterowss\n",
    "\n",
    "    \n",
    "        \n",
    "    # Para o caso da divisao por soma zero. Sera criado um proporcional 1/total de colunas.\n",
    "    # Assim garantindo que a soma da linha da 1.\n",
    "    # O Total de colunas tem que ser respectivo de onde correu a combinacao. Ex. event_pattern_prices\n",
    "#     grid_markov.fillna(1/(grid_markov.shape[1] - 1), inplace=True)\n",
    "#     log.debug(f'GRID FILLNA :{grid_markov}')\n",
    "#     for idx in x[x[x.columns[0]].isna()].index:\n",
    "#         print(idx)\n",
    "    \n",
    "    #Remove a coluna Soma    \n",
    "    del grid_markov['soma']\n",
    "    \n",
    "    log.debug(f'Prova dos Nove - Somatorio deve ser 1 | {grid_markov.T.sum()}')\n",
    "\n",
    "    return grid_markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkvzi5uOVqN9"
   },
   "outputs": [],
   "source": [
    "def build_transition_grid_v1(df: pd.DataFrame, unique_patterns, pattern_column):\n",
    "    '''\n",
    "    build the markov transition grid\n",
    "    '''\n",
    "    patterns  = []\n",
    "    counts    = []\n",
    "    counts_fk = {}\n",
    "    stop      = 0\n",
    "    \n",
    "    event_patterns  = [x for x in df.columns if pattern_column in x  ]\n",
    "\n",
    "    #para cada pattern\n",
    "    for col in event_patterns:\n",
    "\n",
    "        # de\n",
    "        for from_event in unique_patterns:\n",
    "            \n",
    "            # para\n",
    "            for to_event in unique_patterns:\n",
    "                pattern = f'{from_event},{to_event}' # MMM,MlM\n",
    "\n",
    "                # captura a transicao de um estado para outro\n",
    "                ids_matches = df[df[col].str.contains(pattern)]\n",
    "                #print(ids_matches)\n",
    "\n",
    "                found = 0\n",
    "                if len(ids_matches) > 0:\n",
    "                    Event_Pattern = '---'.join(ids_matches[col].values)\n",
    "                    found = Event_Pattern.count(pattern)\n",
    "                    log.debug(f'pattern => {pattern} | ids_matches: {len(ids_matches)} | found: {found} | {stop}')\n",
    "                    \n",
    "                patterns.append(pattern)\n",
    "                counts.append(found)\n",
    "\n",
    "                counts_fk[pattern] = f'{len(ids_matches)}|{found}'\n",
    "\n",
    "            \n",
    "#             stop +=1\n",
    "#             if stop>5:\n",
    "#                 break\n",
    "#                 None\n",
    "#     logging.basicConfig(level=logging.DEBUG)    \n",
    "    return build_grid_markov(patterns, counts, counts_fk)\n",
    "    \n",
    "\n",
    "reset_logging()\n",
    "    \n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# x = build_transition_grid_v1(df6_neg, unique_patterns[194:])\n",
    "# x\n",
    "# # x.T.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes + Def Matriz Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES       = ['production', 'exports', 'prices']\n",
    "\n",
    "def get_markov(df6_pos, df6_neg):\n",
    "\n",
    "    grids_markov = {}\n",
    "\n",
    "    for ref in CLASSES:\n",
    "        print(ref)\n",
    "        pattern_column = f'event_pattern_{ref}'\n",
    "        unique_patterns = get_unique_patterns_V1(X_train[pattern_column].values)\n",
    "\n",
    "        grid_pos = build_transition_grid_v1(df6_pos, unique_patterns, pattern_column) \n",
    "        grids_markov[f'{ref}_positive'] = grid_pos\n",
    "        grid_pos.to_excel(f'grid_alt3_{ref}_positive.xlsx')\n",
    "        print(ref, 'positive')\n",
    "\n",
    "        grid_neg = build_transition_grid_v1(df6_neg, unique_patterns, pattern_column)\n",
    "        grids_markov[f'{ref}_negative'] = grid_neg\n",
    "        grid_neg.to_excel(f'grid_alt3_{ref}_negative.xlsx') \n",
    "        print(ref, 'negative')\n",
    "        \n",
    "    return grids_markov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time grids_markov = get_markov(df6_pos, df6_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grids_markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(grids_markov, open(\"grid_markov.pickle\", \"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pickle.load(open(\"grid_markov.pickle\", \"rb\"))\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz Transição\n",
    " Markov State Transition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://networks.quantecon.org/ch_mcs.html\n",
    "- https://python-advanced.quantecon.org/stationary_densities.html\n",
    "- https://python.quantecon.org/finite_markov.html\n",
    "- https://python.quantecon.org/markov_perf.html\n",
    "- https://www.viralml.com/video-content.html?fm=yt&v=sdp49vTanSk\n",
    "- https://pkghosh.wordpress.com/2015/07/06/customer-conversion-prediction-with-markov-chain-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$logOdds = Σlog( tp(i,j) \\div tn(i,j) )$\n",
    "\n",
    "onde\n",
    "- tp(i,j) = probabilidade de transição para transição do estado i para j para valor de classe positivo (T)\n",
    "- tn(i,j) = transição probabilidade de transição do estado i para j para valor de classe negativo (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log(numerator, denominator):\n",
    "\n",
    "    if numerator <= 0 and denominator <= 0:\n",
    "        log_value = 0\n",
    "    elif denominator <= 0:\n",
    "        log_value = np.log(numerator / 0.00001)\n",
    "    elif numerator <= 0:\n",
    "        log_value = np.log(0.00001 / denominator)\n",
    "    else:\n",
    "        log_value = np.log(numerator / denominator)\n",
    "        \n",
    "    return log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_something(df_validation: pd.DataFrame, \n",
    "                      df_positive: pd.DataFrame, \n",
    "                      df_negative: pd.DataFrame):\n",
    "    \n",
    "    actual = []\n",
    "    predicted = []\n",
    "    \n",
    "    list_positive = list(df_positive)\n",
    "    list_negative = list(df_negative)\n",
    "    total_size = len(df_validation)\n",
    "    \n",
    "    for row_num, seq_id in enumerate(df_validation['Sequence_ID'].values):\n",
    "        patterns = df_validation[df_validation['Sequence_ID'] == seq_id]['events_pattern'].values[0].split(',')\n",
    "        \n",
    "        log.debug(f'patterns: {len(patterns)} | {patterns}' )\n",
    "        \n",
    "        pos = []\n",
    "        neg = []\n",
    "        log_odds = []\n",
    "\n",
    "        for id in range(0, len(patterns) - 1):\n",
    "            \n",
    "#             log.debug(f'compare 1: {patterns[id]} in { list_positive}')\n",
    "#             log.debug(f'compare 2: {patterns[id+1]} in { list_positive}')\n",
    "#             log.debug(f'compare 3: {patterns[id]} in { list_negative}')\n",
    "#             log.debug(f'compare 4: {patterns[id+1]} in { list_negative}')\n",
    "\n",
    "\n",
    "            # get log odds\n",
    "            # logOdds = log(tp(i,j) / tn(i,j)\n",
    "            \n",
    "            if patterns[id] in list_positive and patterns[id+1] in list_positive and \\\n",
    "                patterns[id] in list_negative and patterns[id+1] in list_negative:\n",
    "\n",
    "                numerator = df_positive[patterns[id]][patterns[id+1]]\n",
    "                denominator = df_negative[patterns[id]][patterns[id+1]]\n",
    "                \n",
    "                log_value = safe_log(numerator, denominator)\n",
    "                \n",
    "#                 log.debug(f'numerator: {numerator:.5f} | denominator: {denominator:.5f} | log_value : {log_value:.5f}')\n",
    "\n",
    "            else:\n",
    "                log_value = 0\n",
    "\n",
    "            log_odds.append(log_value)\n",
    "            pos.append(numerator)\n",
    "            neg.append(denominator)\n",
    "            \n",
    "#             break\n",
    "\n",
    "        summarized_log = sum(log_odds)\n",
    "    \n",
    "#         log.debug(f'log_value:{sum(log_odds)}')\n",
    "#         log.debug(f'numerator:{sum(pos)}')\n",
    "#         log.debug(f'denominator:{sum(neg)}')\n",
    "            \n",
    "        print('===' * 30)\n",
    "        outcome = df_validation[df_validation[\"Sequence_ID\"]==seq_id][\"vegetable-oil_price_outcome_direction\"].values[0]\n",
    "        \n",
    "        model_prediction = 1 if summarized_log > 0 else -1\n",
    "        \n",
    "        print(f'row_num: {row_num+1} | seq_id: {seq_id} | Processed : {((row_num+1)/total_size)*100:.2f}%')\n",
    "        print(f'sum(pos): {sum(pos)} | sum(neg): {sum(neg)} | sum(pos)/sum(neg) : {sum(pos)/sum(neg)} ')\n",
    "        print(f'sum(log_odds): {summarized_log}')\n",
    "        \n",
    "        print(f'Outcome: {outcome} | Predict: {model_prediction}')\n",
    "        if model_prediction == outcome:\n",
    "            print('Model Result vs. Actual is **CORRECT**')\n",
    "        else: \n",
    "            print('Model Result vs. Actual is **INCORRECT**')\n",
    "\n",
    "        actual.append(outcome)\n",
    "        predicted.append(model_prediction)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "    return actual, predicted\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "actual, predicted = predict_something(X_test.reset_index(), grid_pos, grid_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X_test.reset_index().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [[0.9, 0.1, 0.0],\n",
    "     [0.4, 0.4, 0.2],\n",
    "     [0.1, 0.1, 0.8]]\n",
    "mc = qe.MarkovChain(P, ('poor', 'middle', 'rich'))\n",
    "mc.is_irreducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = qe.MarkovChain(P)\n",
    "mc.stationary_distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_array = grid_neg.to_numpy()\n",
    "pos_array = grid_pos.to_numpy()\n",
    "\n",
    "pos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = qe.MarkovChain(pos_array)\n",
    "mc.stationary_distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.is_irreducible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array(pos_array)\n",
    "\n",
    "ψ = pos_array[1] #(0.0, 0.2, 0.8)        # Initial condition\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.set(xlim=(0, 1), ylim=(0, 1), zlim=(0, 1),\n",
    "       xticks=(0.25, 0.5, 0.75),\n",
    "       yticks=(0.25, 0.5, 0.75),\n",
    "       zticks=(0.25, 0.5, 0.75))\n",
    "\n",
    "x_vals, y_vals, z_vals = [], [], []\n",
    "for t in range(20):\n",
    "    x_vals.append(ψ[0])\n",
    "    y_vals.append(ψ[1])\n",
    "    z_vals.append(ψ[2])\n",
    "    ψ = ψ @ P\n",
    "\n",
    "ax.scatter(x_vals, y_vals, z_vals, c='r', s=60)\n",
    "ax.view_init(30, 210)\n",
    "\n",
    "mc = qe.MarkovChain(P)\n",
    "ψ_star = mc.stationary_distributions[0]\n",
    "ax.scatter(ψ_star[0], ψ_star[1], ψ_star[2], c='k', s=60)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Vegetable_OIL_Markov.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290.44px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
