{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violando as hipóteses do MLC no Python\n",
    "\n",
    "- https://www.youtube.com/watch?v=Nh1RMs2pL0o\n",
    "\n",
    "Vamos aqui tomar emprestado o arquivo ['card.xlsx'](https://docs.google.com/spreadsheets/d/1rj0LBjPoAQ8lI8nV72deOvUxzZs5s_Ob/edit#gid=107230395), que contém o banco de dados do artigo de David Card (1995) *Using Geographic Variation in College Proximity to Estimate the Return to Schooling*. \n",
    "\n",
    "O arquivo contém um subgrupo dos dados originais, com 29 variáveis, $n=2214$ observações. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos estimar o seguinte modelo:\n",
    "$$\\text{log}(Wage)_i = \\beta_0 + \\beta_1 Educ_i + \\beta_2 Exper_i + \\beta_3 Exper_i^2 + \\beta_4 South_i + \\beta_5 Black_i + \\epsilon_i,$$\n",
    "\n",
    "Assim, começamos montando a matriz X e o vetor y de dados.\n",
    "\n",
    "Note que precisamos temos funções das variáveis $Wage$ e $Exper$ para calcular.\n",
    "\n",
    "Além disso, precisamos incluir a constante no vetor X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2215, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>near2</th>\n",
       "      <th>near4</th>\n",
       "      <th>Educ</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Black</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>South</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Wage</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Exper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>380166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>367470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>380166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>367470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>380166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  near2  near4  Educ  Unnamed: 4  fatheduc  motheduc  Unnamed: 7  \\\n",
       "0   3      0      0    12          27         8         8      380166   \n",
       "1   4      0      0    12          34        14        12      367470   \n",
       "2   5      1      1    11          27        11        12      380166   \n",
       "3   6      1      1    12          34         8         7      367470   \n",
       "4   7      1      1    12          26         9        12      380166   \n",
       "\n",
       "   Unnamed: 8  Unnamed: 9  ...  Unnamed: 19  Unnamed: 20  Black  Unnamed: 22  \\\n",
       "0           1           0  ...            0            0      0            1   \n",
       "1           1           0  ...            0            0      0            1   \n",
       "2           1           0  ...            0            0      0            1   \n",
       "3           1           0  ...            0            0      0            1   \n",
       "4           1           0  ...            0            0      0            1   \n",
       "\n",
       "   South  Unnamed: 24  Wage  Unnamed: 26  Unnamed: 27  Exper  \n",
       "0      0            1   481            0            1      9  \n",
       "1      0            1   721            0            1     16  \n",
       "2      0            1   250            0            1     10  \n",
       "3      0            1   729            0            1     16  \n",
       "4      0            1   500            0            1      8  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from matplotlib.pyplot import figure, plot, bar, draw, hist, legend, draw , subplots\n",
    "# #from numpy.random import randn, rand, standard_t, normal, uniform\n",
    "# from numpy import sqrt, arange, mean, std\n",
    "# from numpy.linalg import inv\n",
    "import pandas as pd                                             ## Carrega o pacote pandas e o chama de pd\n",
    "import numpy as np                                              ## Carrega o pacote numpy e chama de np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "link = 'https://doc-14-20-sheets.googleusercontent.com/export/v8f47es1ueddr6v906ehiub340/jc91mptfbiosdklpmsqs90v1lo/1650744105000/118035206058290454508/108913105810215373705/1rj0LBjPoAQ8lI8nV72deOvUxzZs5s_Ob?format=xlsx&id=1rj0LBjPoAQ8lI8nV72deOvUxzZs5s_Ob&dat=AFCstmqwLJ7IO_d6-DXWsrc7OQouLJrPF_bHvIpRnRz_1iA1L1TqgVpzQPF9Elz7OLsOEqNgepLe96IyRVJtj3gqrbBRqOt-3Wm_bBcT3hrbbOLHQNC7fPyMnQHpPERFtGeAgQzGrKlaKEiyxezXz8gYWOCJNBEE6BcS5pKtOtuyp6BAVbTegk-4TMlda8bOrKHAWfWd8vVWhLaT_0jhVlMx2WvHGyxxkr1JA4A0kxnvBHVvdVE4Uu6E6bUCwUC-AHw8KJuLAPN8jVyKxN_Di3SbsghpujfHBjyWG0TWHhvAMH2kdwMA06La_u4eaPTfTXd5Jz3sw_ArDNV8tiTpOcmZkTPDRW5AJh5KngkN3Jly72OVTTUL-YiRpN_lARDrmNI05ZRQIG9eKbqqydyMay6ioiaErZDECSZfLb-Bjb8oyUklpjc53mOXZj4U_gDAJCv7BmDlGE-cXtRK5WidHYXknPVIc9YzDGj2iyJj4kdd8TT-EqV9DjQkmsX0KV-gpNBjZgCp8EnIz4FgcnV2qArDkqhIse9MXEvrdCKNj-bii3bxlOSUk7Msr2iAjp2ygZlNq_F7x-dz2x8NjVkA6y9QTYUVCe7oheSR16SI09W2dIFyldgwItSfvPE-80O8uswf1j7fte9gCMR0rcY4Qt6PvFzVbxJ9C2-RzcBn5-BdsZ7KjcbK65wandiHMJgfa3qrFh6LxU0s0qVXXRwCmtqyJTQhxsi8AwBsp6Yip6CKXgwqA__1iO4'\n",
    "dados = pd.read_excel('card.xlsx')\n",
    "print(dados.shape)\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listanomes = [\"Educ\",\"Exper\",\"South\",\"Black\"]                   # Cria lista de variáveis\n",
    "X          = dados[listanomes]                                  # Seleciona os dados e salva numa matriz \n",
    "y          = dados[\"Wage\"]                                      # Seleciona a variável dependente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)                                                   # Converte o nível do salário em log(salário)\n",
    "n = len(y)                                                      # Obtém o número de observações\n",
    "y = np.reshape(y,(n,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.17586727],\n",
       "       [6.58063914],\n",
       "       [5.52146092],\n",
       "       ...,\n",
       "       [6.56807791],\n",
       "       [6.15697899],\n",
       "       [5.81413053]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81 256 100 ...  64  25  49]\n",
      "[[ 81]\n",
      " [256]\n",
      " [100]\n",
      " ...\n",
      " [ 64]\n",
      " [ 25]\n",
      " [ 49]]\n"
     ]
    }
   ],
   "source": [
    "Exper2 = np.array(dados[\"Exper\"])**2                              # Seleciona Exper e eleva ao quadrado\n",
    "print(Exper2)\n",
    "print(Exper2[...,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  12.,   9.,  81.,   0.,   0.],\n",
       "       [  1.,  12.,  16., 256.,   0.,   0.],\n",
       "       [  1.,  11.,  10., 100.,   0.,   0.],\n",
       "       ...,\n",
       "       [  1.,  15.,   8.,  64.,   1.,   0.],\n",
       "       [  1.,  16.,   5.,  25.,   1.,   0.],\n",
       "       [  1.,  12.,   7.,  49.,   1.,   0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp1 = Dados[:,0:2]                                             # Seleciona as variáveis Educ e Exper  \n",
    "X_tmp1 = np.hstack([np.ones((n,1)),X_tmp1])                       # Concatena a constante com X_tmp1 \n",
    "X_tmp1 = np.concatenate((X_tmp1,Exper2[...,None]),axis=1)         # Concatena X_tmp1 para agregar Exper^2\n",
    "X      = np.concatenate((X_tmp1,Dados[:,2:]),axis=1)              # Concatena X_tmp1 com \"South\",\"Black\"\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, atualizamos a lista de variávels para:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listanomes = [\"Const\",\"Educ\",\"Exper\",\"Exper^2\",\"South\",\"Black\"]     # Atualiza a lista de variáveis\n",
    "k          = len(X[0])                                              # Obtém o número de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar pela estimação OLS de $\\beta = (\\beta_0,\\beta_1,\\beta_2,\\beta_3, \\beta_4, \\beta_5)'$, que denotaremos por $\\beta_{ols}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimação OLS de $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================\n",
      "-----------------------------------------------------------------------------\n",
      "                                Estimação OLS\n",
      "-----------------------------------------------------------------------------\n",
      "R2:     [0.23730627]     Graus de liberdade    2209\n",
      "R2_adj: [0.23557993]     Número de Observações 2215\n",
      "s^2:    [0.14760106]     Variável dependente   log(Wage)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "               Coef        S.E.       t-Stat     S.E. Rob     t-Rob\n",
      "     Const    4.7351      0.0796     59.4716      0.0837     56.5519\n",
      "      Educ    0.0802      0.0041     19.4582      0.0043     18.5463\n",
      "     Exper    0.0893      0.0081     11.0743      0.0081     10.9738\n",
      "   Exper^2   -0.0025      0.0004     -6.0645      0.0004     -6.0905\n",
      "     South   -0.1359      0.0178     -7.6560      0.0177     -7.6730\n",
      "     Black   -0.1591      0.0238     -6.6918      0.0238     -6.6928\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Beta_ols= inv(X.T @ X) @ (X.T @ y)                  # Estimativa OLS para Beta\n",
    "e_hat   = y - X @ Beta_ols;                         # resíduo da regressão i\n",
    "s2_ols  = (e_hat.T @ e_hat)/(n-k);                  # estimativa de s2 para a amostra i\n",
    "AVAR_ols= s2_ols * inv(X.T @ X);                    # Estimando a Variância esférica\n",
    "dp      = sqrt(np.diag(AVAR_ols));                  # Computa o desvio padrão\n",
    "tsta_ols= Beta_ols.T/dp                             # Computa a estatística t.\n",
    "D       = np.diag(e_hat[:,0])**2                    # Para utilizar o comando diag, precisamos converter e_hat em nx1. \n",
    "Whit_ols= inv(X.T @ X) @ X.T @ D @ X @ inv(X.T @ X) # Matriz Robusta de White    \n",
    "se_r_ols= sqrt(np.diag(Whit_ols));                  # SE_robustos\n",
    "t_r_ols = Beta_ols.T/se_r_ols;                      # Estatística t com SE_Robusto\n",
    "\n",
    "R2=1-((e_hat.T@e_hat)/n)/np.var(y)                  # R_2\n",
    "\n",
    "R2_adj=1-((e_hat.T@e_hat)/(n-k))/(np.var(y)*n/(n-1))               \n",
    "R2_adj;                                             #R_2 Ajustado\n",
    "\n",
    "print('\\n=============================================================================')\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('                                Estimação OLS');\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('R2:    ' , R2[0],    '    Graus de liberdade   ', n-k)\n",
    "print('R2_adj:' , R2_adj[0],'    Número de Observações', n )\n",
    "print('s^2:   ' , s2_ols[0],    '    Variável dependente  ', \"log(Wage)\")\n",
    "print('\\n---------------------------------------------------------------------------')\n",
    "print('               Coef        S.E.       t-Stat     S.E. Rob     t-Rob')\n",
    "for i in range(k):\n",
    "    tuplaprint=(Beta_ols[i],dp[i],tsta_ols[0,i],se_r_ols[i],t_r_ols[0,i])                     # cria uma tupla com os resultados\n",
    "    print(\"%10s\" % listanomes[i],\" %8.4f    %8.4f    %8.4f    %8.4f    %8.4f\" % tuplaprint)  # imprime cada coeficiente\n",
    "\n",
    "print('\\n---------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos comparar com os resultados do pacote do statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.237\n",
      "Model:                            OLS   Adj. R-squared:                  0.236\n",
      "Method:                 Least Squares   F-statistic:                     137.5\n",
      "Date:                Sat, 23 Apr 2022   Prob (F-statistic):          3.65e-127\n",
      "Time:                        18:11:06   Log-Likelihood:                -1021.0\n",
      "No. Observations:                2215   AIC:                             2054.\n",
      "Df Residuals:                    2209   BIC:                             2088.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.7351      0.080     59.472      0.000       4.579       4.891\n",
      "x1             0.0802      0.004     19.458      0.000       0.072       0.088\n",
      "x2             0.0893      0.008     11.074      0.000       0.074       0.105\n",
      "x3            -0.0025      0.000     -6.065      0.000      -0.003      -0.002\n",
      "x4            -0.1359      0.018     -7.656      0.000      -0.171      -0.101\n",
      "x5            -0.1591      0.024     -6.692      0.000      -0.206      -0.112\n",
      "==============================================================================\n",
      "Omnibus:                       50.607   Durbin-Watson:                   1.835\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               62.572\n",
      "Skew:                          -0.294   Prob(JB):                     2.59e-14\n",
      "Kurtosis:                       3.576   Cond. No.                     1.12e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.12e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm                                            ## Carrega o statsmodels como sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std   ## \n",
    "ols_model = sm.OLS(y,X)\n",
    "ols_results = ols_model.fit()\n",
    "print(ols_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS FK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp():\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    modelo = LinearRegression()\n",
    "    \n",
    "    # criando um dataframe com 3 variveis\n",
    "    X = dados[['temp_max', 'chuva', 'fds']]\n",
    "    X.head()\n",
    "temp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimação FGLS de $\\beta$\n",
    "\n",
    "Vamos agora estimar $\\beta$ utilizando o estimador de dois estágios FGLS. Procederemos o seguinte algorítmo:\n",
    "\n",
    "1. Estime a equação $y_i=x_i'\\beta + \\epsilon_i$ por OLS e compute os resíduos, $e_i$.\n",
    "1. Regrida $e_i^2$ sobre $x_i$ e obtenha uma estimativa OLS para $\\hat{\\alpha}$, que está associado à regressão $$e_i^2 =x_i'\\alpha + u_i$$\n",
    "\n",
    "1. Divida $y_i$ e $x_i$ por $\\tfrac{1}{\\sqrt{x_i'\\hat{\\alpha}}}$ e estime o modelo por WLS usando a equação $\\tilde{y}_i=\\tilde{x}_i\\beta +\\tilde{\\epsilon}_i$.\n",
    "1.Alternativamente, compute $$\\widehat{\\beta}(V) = (X'(V(\\hat{\\alpha}))^{-1}X)^{-1}X'(V(\\hat{\\alpha}))^{-1}y,$$\n",
    "    em que\n",
    "    $$V_{(n \\times n)}(\\hat{\\alpha})=\\begin{bmatrix}\n",
    "x_1'\\hat{\\alpha} & \\cdots  &0 \\\\ \n",
    "\\vdots & \\ddots & \\vdots\\\\ \n",
    "0 & \\cdots & x'_n\\hat{\\alpha}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Como já temos $\\beta_{ols}$ e $e_i$ da regressão acima, basta prosseguimos com os passos 2 e 3 ou 2 e 4. Lembre-se que, após a transformação, $s^2=1$ dada a normalização.\n",
    "\n",
    "Além disso, \n",
    "$$\\widehat{\\text{Avar}(\\widehat{\\beta}(V)|X)}=\\Bigg(X'V^{-1}X\\Bigg)^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1466638 ],\n",
       "       [0.13791917],\n",
       "       [0.14528563],\n",
       "       ...,\n",
       "       [0.14742999],\n",
       "       [0.14918608],\n",
       "       [0.14631326]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtendo alpha:\n",
    "alfafit  = X @ inv(X.T @ X) @ (X.T @ (e_hat**2))         # Obtém o valor predito usando a matriz de projeção\n",
    "alfafit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a matriz V é, na verdade, $\\text{diag}(X\\hat{\\alpha})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1466638 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.13791917, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.14528563, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.14742999, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.14918608,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.14631326]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V       = np.matrix(alfafit)      # Para isso, utilizamos o comando matrix, que converte os dados em matriz de formatos arbitrários\n",
    "V       = np.diag(V.A1)           # e extraímos a \"matriz 1-D\" do vetor e_hat. Em seguida, elevamos ao quadrado cada elemento\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat   = y/(alfafit**.5) \n",
    "X_hat   = X/(alfafit**.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================\n",
      "-----------------------------------------------------------------------------\n",
      "                                Estimação WGLS\n",
      "-----------------------------------------------------------------------------\n",
      "R2:     [-4.18114865]     Graus de liberdade    2209\n",
      "R2_adj: [-4.19287602]     Número de Observações 2215\n",
      "s^2:    [1.00268691]     Variável dependente   log(Wage)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "               Coef        S.E.       t-Stat       S.E. Rob     t-Rob\n",
      "     Const    4.7433      0.0793      59.8479       0.0793      59.8479\n",
      "      Educ    0.0799      0.0041      19.4451       0.0041      19.4451\n",
      "     Exper    0.0882      0.0080      11.0605       0.0080      11.0605\n",
      "   Exper^2   -0.0024      0.0004      -6.0403       0.0004      -6.0403\n",
      "     South   -0.1367      0.0177      -7.7244       0.0177      -7.7244\n",
      "     Black   -0.1620      0.0239      -6.7850       0.0239      -6.7850\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Beta_gls= inv(X.T @ inv(V) @ X) @ (X.T @ inv(V) @ y)     # Estimação FGLS\n",
    "Beta_gl1= inv(X_hat.T @ X_hat)  @ (X_hat.T @ y_hat)      # Estimação FGLS\n",
    "e_hat   = y_hat - X_hat @ Beta_gls;                      # resíduo da regressão i\n",
    "s2_gls  = (e_hat.T @ e_hat)/(n-k);                       # estimativa de s2 para a amostra i\n",
    "AVAR_gls= inv(X.T @ inv(V) @ X);                         # Estimando a Variância esférica\n",
    "dp      = sqrt(np.diag(AVAR_gls));                       # Computa o desvio padrão\n",
    "tsta_gls= Beta_gls.T/dp                                  # Computa a estatística t.\n",
    "#D       = np.diag(e_hat[:,0])**2                        # Eleva o resíduo ao quadrado e diagonaliza o vetor resultante\n",
    "AVA2_gls= inv(X_hat.T @ X_hat)                           # Mesma de antes. Apenas confirmando o resultado. Não é White!\n",
    "se_r_gls= sqrt(np.diag(AVA2_gls));                          \n",
    "t_r_gls = Beta_gls.T/se_r_gls;\n",
    "\n",
    "R2=1-((e_hat.T@e_hat)/n)/np.var(y)\n",
    "R2\n",
    "R2_adj=1-((e_hat.T@e_hat)/(n-k))/(np.var(y)*n/(n-1))               \n",
    "R2_adj\n",
    "\n",
    "print('\\n=============================================================================')\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('                                Estimação WGLS');\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('R2:    ' , R2[0],    '    Graus de liberdade   ', n-k)\n",
    "print('R2_adj:' , R2_adj[0],'    Número de Observações', n )\n",
    "print('s^2:   ' , s2_gls[0],    '    Variável dependente  ', \"log(Wage)\")\n",
    "print('\\n---------------------------------------------------------------------------')\n",
    "print('               Coef        S.E.       t-Stat       S.E. Rob     t-Rob')\n",
    "for i in range(k):\n",
    "    tuplaprint=(Beta_gls[i],dp[i],tsta_gls[0,i],se_r_gls[i],t_r_gls[0,i])                     # cria uma tupla com os resultados\n",
    "    print(\"%10s\" % listanomes[i],\" %8.4f    %8.4f    %9.4f    %9.4f    %9.4f\" % tuplaprint)  # imprime cada coeficiente\n",
    "\n",
    "print('\\n---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endogeneidade\n",
    "Vamos assumir agora que $Educ$ é endógena, mas que temos um bom instrumento pela variável $near4$. \n",
    "Assim, vamos estimar o modelo com uma variável endógena e um instrumento, configurando o caso exatamente identificado.\n",
    "\n",
    "Ou seja, para o indivíduo $i$, o modelo é:\n",
    "\n",
    "\\begin{equation}\n",
    "y_i=x_i'\\beta +u_i\n",
    "\\end{equation}\n",
    "em que $$\\underbrace{x_i}_{(K\\times 1)} = (1, \\underbrace{Educ_i}_{\\text{endógena}}, Exper_i, Exper_i^2, South_i, Black_i)$$ \n",
    "\n",
    "e o **vetor de instrumentos** $$\\underbrace{z_i}_{(L=K\\times 1)} = (1, \\underbrace{near4_i}_{\\text{instrumento}}, Exper_i, Exper_i^2, South_i, Black_i)$$\n",
    "\n",
    "\n",
    "Assim, o primeiro passo é construir o vetor $Z$. Neste caso é simples, pois ele é muito parecido com X. Apenas precisamos trocar os dados na coluna do X que corresponde à variável Educ pelos dados de near4. Isso é feito a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "Z      = copy.deepcopy(X);              # Este comando é necessário, pois Z=X cria uma nova referência à X e não uma cópia de X\n",
    "Z[:,1] = np.array(dados[\"near4\"]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0.,   9.,  81.,   0.,   0.],\n",
       "       [  1.,   0.,  16., 256.,   0.,   0.],\n",
       "       [  1.,   1.,  10., 100.,   0.,   0.],\n",
       "       ...,\n",
       "       [  1.,   1.,   8.,  64.,   1.,   0.],\n",
       "       [  1.,   1.,   5.,  25.,   1.,   0.],\n",
       "       [  1.,   1.,   7.,  49.,   1.,   0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  12.,   9.,  81.,   0.,   0.],\n",
       "       [  1.,  12.,  16., 256.,   0.,   0.],\n",
       "       [  1.,  11.,  10., 100.,   0.,   0.],\n",
       "       ...,\n",
       "       [  1.,  15.,   8.,  64.,   1.,   0.],\n",
       "       [  1.,  16.,   5.,  25.,   1.,   0.],\n",
       "       [  1.,  12.,   7.,  49.,   1.,   0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que sabemos que estamos ok, basta-nos adaptarmos os códigos que já temos, pois \n",
    "\\begin{equation}\n",
    "    \\hat{\\beta}_{IV} = \\bigg( \\frac{1}{n}\\sum_{i=1}^n z_i x_i'\\Bigg)^{-1} \\Bigg( \\frac{1}{n}\\sum_{i=1}^n z_i y_i\\Bigg) = (Z'X)^{-1}(Z'y)\n",
    "\\end{equation}\n",
    "em que $Z$ e $X$ são $n \\times K$ e $y$ é $n \\times 1$.\n",
    "\n",
    "E, sob variância esféria,\n",
    "\n",
    "$$\\widehat{\\text{Avar}(\\hat{\\beta}_{IV})} =s^2 (Z'X)^{-1} (Z'Z) (X'Z)^{-1} $$\n",
    "\n",
    "ou, c.c.,\n",
    "\n",
    "$$\\widehat{\\text{Avar}(\\hat{\\beta}_{IV})} = (Z'X)^{-1} (Z'\\hat{D} Z) (X'Z)^{-1} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================\n",
      "-----------------------------------------------------------------------------\n",
      "                                Estimação IV\n",
      "-----------------------------------------------------------------------------\n",
      "R2:     [-0.17483072]     Graus de liberdade    2209\n",
      "R2_adj: [-0.17748991]     Número de Observações 2215\n",
      "s^2:    [0.22736028]     Variável dependente   log(Wage)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "               Coef        S.E.       t-Stat     S.E. Rob     t-Rob\n",
      "     Const    2.2659      1.0254      2.2097      0.9999      2.2661\n",
      "      Educ    0.2226      0.0591      3.7676      0.0577      3.8610\n",
      "     Exper    0.1507      0.0273      5.5255      0.0270      5.5853\n",
      "   Exper^2   -0.0027      0.0005     -5.2476      0.0006     -4.7070\n",
      "     South   -0.0856      0.0303     -2.8270      0.0294     -2.9101\n",
      "     Black   -0.0359      0.0589     -0.6097      0.0562     -0.6391\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Beta_iv = inv(Z.T @ X) @ (Z.T @ y)            # Estimador para IV com L=K \n",
    "e_hat   = y-X@Beta_iv;                        # resíduo da regressão i\n",
    "s2_iv   = (e_hat.T@e_hat)/(n-k);              # estimativa de s2 para a amostra i\n",
    "AVAR_iv = s2_iv*inv(Z.T@X)@Z.T@Z@inv(X.T@Z);  # Estimando a Variância esférica\n",
    "dp      = sqrt(np.diag(AVAR_iv));             # Computa o desvio padrão\n",
    "tsta_iv = Beta_iv.T/dp                        # Computa a estatística t.\n",
    "D       = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    D[i,i] = e_hat[i,0]**2\n",
    "    \n",
    "Whit_iv = inv(Z.T@X)@(Z.T@D@Z)@inv(X.T@Z)\n",
    "se_r_iv = sqrt(np.diag(Whit_iv));\n",
    "t_r_iv  = Beta_iv.T/se_r_iv;\n",
    "\n",
    "R2=1-((e_hat.T@e_hat)/n)/np.var(y)\n",
    "R2\n",
    "R2_adj=1-((e_hat.T@e_hat)/(n-k))/(np.var(y)*n/(n-1))               \n",
    "R2_adj\n",
    "\n",
    "print('\\n=============================================================================')\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('                                Estimação IV');\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('R2:    ' , R2[0],    '    Graus de liberdade   ', n-k)\n",
    "print('R2_adj:' , R2_adj[0],'    Número de Observações', n )\n",
    "print('s^2:   ' , s2_iv[0],    '    Variável dependente  ', \"log(Wage)\")\n",
    "print('\\n---------------------------------------------------------------------------')\n",
    "print('               Coef        S.E.       t-Stat     S.E. Rob     t-Rob')\n",
    "for i in range(k):\n",
    "    tuplaprint=(Beta_iv[i],dp[i],tsta_iv[0,i],se_r_iv[i],t_r_iv[0,i])                     # cria uma tupla com os resultados\n",
    "    print(\"%10s\" % listanomes[i],\" %8.4f    %8.4f    %8.4f    %8.4f    %8.4f\" % tuplaprint)  # imprime cada coeficiente\n",
    "\n",
    "print('\\n---------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos então confirmar os resultados no Python.\n",
    "\n",
    "Para isso, carregamos os pacotes de estimação GMM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                      -0.175\n",
      "Model:                         IV2SLS   Adj. R-squared:                 -0.177\n",
      "Method:                     Two Stage   F-statistic:                     42.92\n",
      "                        Least Squares   Prob (F-statistic):           2.49e-42\n",
      "Date:                Sat, 21 Nov 2020                                         \n",
      "Time:                        16:12:29                                         \n",
      "No. Observations:                2215                                         \n",
      "Df Residuals:                    2209                                         \n",
      "Df Model:                           5                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.2659      1.025      2.210      0.027       0.255       4.277\n",
      "x1             0.2226      0.059      3.768      0.000       0.107       0.338\n",
      "x2             0.1507      0.027      5.525      0.000       0.097       0.204\n",
      "x3            -0.0027      0.001     -5.248      0.000      -0.004      -0.002\n",
      "x4            -0.0856      0.030     -2.827      0.005      -0.145      -0.026\n",
      "x5            -0.0359      0.059     -0.610      0.542      -0.151       0.080\n",
      "==============================================================================\n",
      "Omnibus:                       26.284   Durbin-Watson:                   1.858\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.802\n",
      "Skew:                          -0.178   Prob(JB):                     7.54e-08\n",
      "Kurtosis:                       3.479   Cond. No.                     1.12e+03\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "IV_model = IV2SLS(y,X,Z)\n",
    "IV_results = IV_model.fit()\n",
    "print(IV_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora instrumentalizar $Educ$ com $near4$, $near2$, $fatheduc$ e $motheduc$.\n",
    "\n",
    "Assim, vamos estimar o modelo com uma variável endógena e quatro instrumentos, configurando o caso sobre-identificado.\n",
    "\n",
    "Ou seja, para o indivíduo $i$, o modelo é:\n",
    "\n",
    "\\begin{equation}\n",
    "y_i=x_i'\\beta +u_i\n",
    "\\label{eq:modelxb}\n",
    "\\end{equation}\n",
    "em que $$\\underbrace{x_i}_{(K\\times 1)} = (1, \\underbrace{Educ_i}_{\\text{endógena}}, Exper_i, Exper_i^2, South_i, Black_i)$$ \n",
    "\n",
    "e o **vetor de instrumentos** $$\\underbrace{z_i}_{(L\\times 1)} = (1, \\underbrace{near4_i, near2_i,  fatheduc_i, motheduc_i}_{\\text{instrumentos}}, Exper_i, Exper_i^2, South_i, Black_i),$$\n",
    "com $L>K$.\n",
    "\n",
    "Assim, o primeiro passo é construir o vetor $Z$. Neste caso é um pouco mais trabalhoso e convém montar um vetor adicional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "listainstrumentos = [\"near4\",\"near2\",\"fatheduc\",\"motheduc\"]  # Cria lista de variáveis instrumentais\n",
    "instrumentos      = np.array(dados[listainstrumentos])       # Seleciona os dados e salva numa matriz temporária\n",
    "Z                 = np.concatenate((np.ones((n,1)),instrumentos,Exper2[...,None],Dados[:,1:]),axis=1)                       # Concatena a constante com X_tmp1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que no caso em que $L>K$, procedemos em dois estágios:\n",
    "\n",
    "Procedimento de dois estágios:\n",
    "\n",
    "1. *Primeiro Estágio*: Regredir $X$ em $Z$ e salvar os valores preditos, $\\hat{X}$.\n",
    "Lembre-se de que esta regressão equivale a pré-multiplicar $X$ pela matriz de projeção, neste caso baseada em $Z$:\n",
    "$$ \\hat{X} = Z(Z'Z)^{-1}Z'X = P_ZX$$\n",
    "1. *Segundo Estágio*: Regridir $y$ em $\\hat{X}$ usando o estimador de OLS:\n",
    "\\begin{equation}\n",
    "    {\\beta}_{2SLS} = (\\hat{X}'\\hat{X})^{-1}(\\hat{X}'y)\n",
    "\\end{equation}\n",
    "\n",
    "Assim, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_z = Z@inv(Z.T@Z)@Z.T\n",
    "X_hat = P_z@X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entretanto, a Avar fica um mais envolvida:\n",
    "\\begin{align*}\n",
    "\\widehat{\\text{Avar}(\\beta_{2SLS})} &=     \n",
    "(X'Z(Z'Z)^{-1}Z'X)^{-1}(X'Z(Z'Z)^{-1}Z \\\\\n",
    " &\\quad \\quad \\quad\\boldsymbol{{D}}Z(Z'Z)^{-1}Z'X)(X'Z(Z'Z)^{-1}Z'X)^{-1}\\\\\n",
    " &=(\\hat{X}'\\hat{X})^{-1} \\hat{X}'\\boldsymbol{{D}} \\hat{X} (\\hat{X}'\\hat{X})^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "Note que, sob homocedasticidade, $\\boldsymbol{D_u}=s^2I_n$ e, assim, \n",
    "\\begin{align*}\n",
    "\\widehat{\\text{Avar}(\\beta_{2SLS})} &= s^2(X'Z(Z'Z)^{-1}Z'X)^{-1} \\\\\n",
    "                                    &= s^2(\\hat{X}'\\hat{X})^{-1} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================\n",
      "-----------------------------------------------------------------------------\n",
      "                                Estimação 2SLS\n",
      "-----------------------------------------------------------------------------\n",
      "R2:     [0.208881]       Graus de liberdade    2209\n",
      "R2_adj: [0.20709032]     Número de Observações 2215\n",
      "s^2:    [0.15310209]     Variável dependente   log(Wage)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "               Coef        S.E.       t-Stat     S.E. Rob     t-Rob\n",
      "     Const    4.0867      0.2193     18.6313      0.2235     18.2862\n",
      "      Educ    0.1176      0.0125      9.4226      0.0128      9.1812\n",
      "     Exper    0.1054      0.0097     10.9253      0.0098     10.7344\n",
      "   Exper^2   -0.0025      0.0004     -6.0930      0.0004     -5.8647\n",
      "     South   -0.1227      0.0185     -6.6148      0.0185     -6.6396\n",
      "     Black   -0.1267      0.0263     -4.8259      0.0263     -4.8198\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Beta_2sls = inv(X_hat.T@X_hat)@(X_hat.T@y)\n",
    "e_hat     = y-X@Beta_2sls;                  # resíduo da regressão i\n",
    "s2_2sls   = (e_hat.T@e_hat)/(n-k);          # estimativa de s2 para a amostra i\n",
    "AVAR_2sls = s2_2sls*inv(X_hat.T@X)          # Estimando a Variância esférica\n",
    "dp        = sqrt(np.diag(AVAR_2sls));       # Computa o desvio padrão\n",
    "tsta_2sls = Beta_2sls.T/dp                  # Computa a estatística t.\n",
    "D         = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    D[i,i] = e_hat[i,0]**2\n",
    "    \n",
    "Whit_2sls = inv(X_hat.T@X_hat)@(X_hat.T@D@X_hat)@inv(X_hat.T@X_hat)\n",
    "se_r_2sls = sqrt(np.diag(Whit_2sls));\n",
    "t_r_2sls  = Beta_2sls.T/se_r_2sls;\n",
    "\n",
    "R2=1-((e_hat.T@e_hat)/n)/np.var(y)\n",
    "R2\n",
    "R2_adj=1-((e_hat.T@e_hat)/(n-k))/(np.var(y)*n/(n-1))               \n",
    "R2_adj\n",
    "\n",
    "print('\\n=============================================================================')\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('                                Estimação 2SLS');\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('R2:    ' , R2[0],    '      Graus de liberdade   ', n-k)\n",
    "print('R2_adj:' , R2_adj[0],'    Número de Observações', n )\n",
    "print('s^2:   ' , s2_2sls[0],    '    Variável dependente  ', \"log(Wage)\")\n",
    "print('\\n---------------------------------------------------------------------------')\n",
    "print('               Coef        S.E.       t-Stat     S.E. Rob     t-Rob')\n",
    "for i in range(k):\n",
    "    tuplaprint=(Beta_2sls[i],dp[i],tsta_2sls[0,i],se_r_2sls[i],t_r_2sls[0,i])                # cria uma tupla com os resultados\n",
    "    print(\"%10s\" % listanomes[i],\" %8.4f    %8.4f    %8.4f    %8.4f    %8.4f\" % tuplaprint)  # imprime cada coeficiente\n",
    "\n",
    "print('\\n---------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV_model = IV2SLS(y,X,Z)\n",
    "IV_results = IV_model.fit()\n",
    "print(IV_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3SLS - GMM Eficiente\n",
    "\n",
    "Uma vez que temos disponível uma estimativa não enviesada de $\\beta_{2sls}$, podemos atingir maior eficiência se trocarmos a matriz de ponderação do GMM para a matriz \n",
    "$$W = (Z'D^{-1}Z)^{-1}$$\n",
    "\n",
    "Com isso obtendo estimativas a partir do estimador 3SLS.\n",
    "\n",
    "Assim, o estimador 3SLS é dado por:\n",
    "    $$\\hat{\\beta}_{3sls}=  \\bigg(X'Z(Z'\\hat{D}Z)^{-1}Z'X\\bigg)^{-1} X'Z(Z'\\hat{D}Z)^{-1}Z'y$$\n",
    "\n",
    "E é eficiente, pois sua matriz de variância é se simplifica para:\n",
    "\\begin{align*}\n",
    "\\widehat{\\text{Var}(\\hat{\\beta_{3sls}}|X,Z)}  &= \\Big(X'Z(Z'\\hat{D}Z)^{-1}Z'X\\Big)^{-1} X'Z(Z'\\hat{D}Z)^{-1} \\\\ \n",
    " &\\times Z'\\hat{D} Z(Z'\\hat{D}Z)^{-1}Z'X \\Big(X'Z (Z'\\hat{D}Z)^{-1} Z'X\\Big)^{-1}\\\\\n",
    " &= (X'Z(Z'\\hat{D}Z)^{-1}Z'X)^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "Note que a matriz D associada à $\\beta_{2sls}$ ainda está na memória. Assim, não precisamos recomputá-la.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = inv(Z.T @ D @ Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================\n",
      "-----------------------------------------------------------------------------\n",
      "                                Estimação 3SLS\n",
      "-----------------------------------------------------------------------------\n",
      "R2:     [0.20972039]     Graus de liberdade    2209\n",
      "R2_adj: [0.20793162]     Número de Observações 2215\n",
      "s^2:    [0.15293964]     Variável dependente   log(Wage)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "               Coef        S.E.       t-Stat     S.E. Rob     t-Rob\n",
      "     Const    4.0944      0.2231     18.3519      0.2231     18.3519\n",
      "      Educ    0.1170      0.0128      9.1521      0.0128      9.1521\n",
      "     Exper    0.1054      0.0098     10.7283      0.0098     10.7283\n",
      "   Exper^2   -0.0025      0.0004     -5.8844      0.0004     -5.8844\n",
      "     South   -0.1234      0.0185     -6.6806      0.0185     -6.6806\n",
      "     Black   -0.1288      0.0261     -4.9323      0.0261     -4.9323\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Beta_3sls = inv(X.T @ Z @ W @ Z.T @ X) @ (X.T @ Z @ W @ Z.T @ y) # Computa o Beta de 3SLS\n",
    "e_hat     = y-X@Beta_3sls;                  # resíduo da regressão i\n",
    "s2_3sls   = (e_hat.T@e_hat)/(n-k);          # estimativa de s2 para a amostra i\n",
    "AVAR_3sls = inv(X.T@Z@W@Z.T@X)              # Avar de 3SLS\n",
    "dp        = sqrt(np.diag(AVAR_3sls));       # Computa o desvio padrão\n",
    "tsta_3sls = Beta_3sls.T/dp                  # Computa a estatística t.\n",
    "D         = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    D[i,i] = e_hat[i,0]**2\n",
    "    \n",
    "Whit_3sls = inv(X.T@Z@W@Z.T@X)              # Aqui não faz sentido, pois já foi ponderado por D.\n",
    "se_r_3sls = sqrt(np.diag(Whit_3sls));\n",
    "t_r_3sls  = Beta_3sls.T/se_r_3sls;\n",
    "\n",
    "R2=1-((e_hat.T@e_hat)/n)/np.var(y)\n",
    "R2\n",
    "R2_adj=1-((e_hat.T@e_hat)/(n-k))/(np.var(y)*n/(n-1))               \n",
    "R2_adj\n",
    "\n",
    "print('\\n=============================================================================')\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('                                Estimação 3SLS');\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('R2:    ' , R2[0],    '    Graus de liberdade   ', n-k)\n",
    "print('R2_adj:' , R2_adj[0],'    Número de Observações', n )\n",
    "print('s^2:   ' , s2_3sls[0],    '    Variável dependente  ', \"log(Wage)\")\n",
    "print('\\n---------------------------------------------------------------------------')\n",
    "print('               Coef        S.E.       t-Stat     S.E. Rob     t-Rob')\n",
    "for i in range(k):\n",
    "    tuplaprint=(Beta_3sls[i],dp[i],tsta_3sls[0,i],se_r_3sls[i],t_r_3sls[0,i])                # cria uma tupla com os resultados\n",
    "    print(\"%10s\" % listanomes[i],\" %8.4f    %8.4f    %8.4f    %8.4f    %8.4f\" % tuplaprint)  # imprime cada coeficiente\n",
    "\n",
    "print('\\n---------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.209\n",
      "Model:                         IV2SLS   Adj. R-squared:                  0.207\n",
      "Method:                     Two Stage   F-statistic:                     77.28\n",
      "                        Least Squares   Prob (F-statistic):           7.63e-75\n",
      "Date:                Sat, 21 Nov 2020                                         \n",
      "Time:                        16:37:00                                         \n",
      "No. Observations:                2215                                         \n",
      "Df Residuals:                    2209                                         \n",
      "Df Model:                           5                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.0867      0.219     18.631      0.000       3.657       4.517\n",
      "x1             0.1176      0.012      9.423      0.000       0.093       0.142\n",
      "x2             0.1054      0.010     10.925      0.000       0.087       0.124\n",
      "x3            -0.0025      0.000     -6.093      0.000      -0.003      -0.002\n",
      "x4            -0.1227      0.019     -6.615      0.000      -0.159      -0.086\n",
      "x5            -0.1267      0.026     -4.826      0.000      -0.178      -0.075\n",
      "==============================================================================\n",
      "Omnibus:                       50.038   Durbin-Watson:                   1.847\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               64.022\n",
      "Skew:                          -0.280   Prob(JB):                     1.25e-14\n",
      "Kurtosis:                       3.616   Cond. No.                     1.12e+03\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "IV_model   = IV2SLS(y,X,Z)\n",
    "IV_results = IV_model.fit()\n",
    "print(IV_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de Endogeneidade\n",
    "### Hausman-Wu\n",
    "Como $L>K$, podemos testar se $Educ$ é, de fato, endógena\n",
    "\n",
    "Para tanto, primeiro obtemos o resíduo da regressão de $Educ$ em seus instrumentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res_Maker  = np.eye(n)-P_z;\n",
    "eta        = Res_Maker@X[:,1]\n",
    "eta        = np.reshape(eta,(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_h        = np.concatenate((X,eta),axis=1)\n",
    "listanomes = listanomes + [\"eta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================\n",
      "-----------------------------------------------------------------------------\n",
      "                             Teste - Hauman-Wu\n",
      "                      S.E. homocedasticos e robustos\n",
      "-----------------------------------------------------------------------------\n",
      "R2:     [0.24093223]     Graus de liberdade    2209\n",
      "R2_adj: [0.2392141]     Número de Observações 2215\n",
      "s^2:    [0.14689934]     Variável dependente   log(Wage)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "               Coef        S.E.       t-Stat     S.E. Rob     t-Rob\n",
      "     Const    4.0867      0.2149     19.0206      0.2214     18.4574\n",
      "      Educ    0.1176      0.0122      9.6195      0.0127      9.2496\n",
      "     Exper    0.1054      0.0095     11.1536      0.0095     11.0895\n",
      "   Exper^2   -0.0025      0.0004     -6.2203      0.0004     -6.1990\n",
      "     South   -0.1227      0.0182     -6.7530      0.0183     -6.7223\n",
      "     Black   -0.1267      0.0257     -4.9267      0.0261     -4.8594\n",
      "       eta   -0.0422      0.0130     -3.2484      0.0136     -3.0944\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Beta_haus = inv(X_h.T@X_h)@(X_h.T@y)\n",
    "e_hat     = y-X_h@Beta_haus;               # resíduo da regressão i\n",
    "s2_haus   = (e_hat.T@e_hat)/(n-k);         # estimativa de s2 para a amostra i\n",
    "AVAR_haus = s2_haus*inv(X_h.T@X_h)         # Estimando a Variância esférica\n",
    "dp        = sqrt(np.diag(AVAR_haus));      # Computa o desvio padrão\n",
    "tsta_haus = Beta_haus.T/dp                 # Computa a estatística t.\n",
    "D         = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    D[i,i] = e_hat[i,0]**2\n",
    "    \n",
    "Whit_haus = inv(X_h.T @ X_h) @ (X_h.T @ D @ X_h) @ inv(X_h.T @ X_h)\n",
    "se_r_haus = sqrt(np.diag(Whit_haus));\n",
    "t_r_haus  = Beta_haus.T/se_r_haus;\n",
    "\n",
    "R2=1-((e_hat.T @ e_hat)/n)/np.var(y)\n",
    "R2\n",
    "R2_adj=1-((e_hat.T @ e_hat)/(n-k))/(np.var(y)*n/(n-1))               \n",
    "R2_adj\n",
    "\n",
    "print('\\n=============================================================================')\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('                             Teste - Hauman-Wu');\n",
    "print('                      S.E. homocedasticos e robustos');\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('R2:    ' , R2[0],    '    Graus de liberdade   ', n-k)\n",
    "print('R2_adj:' , R2_adj[0],'    Número de Observações', n )\n",
    "print('s^2:   ' , s2_haus[0],    '    Variável dependente  ', \"log(Wage)\")\n",
    "print('\\n---------------------------------------------------------------------------')\n",
    "print('               Coef        S.E.       t-Stat     S.E. Rob     t-Rob')\n",
    "for i in range(k+1):\n",
    "    tuplaprint=(Beta_haus[i],dp[i],tsta_haus[0,i],se_r_haus[i],t_r_haus[0,i])                # cria uma tupla com os resultados\n",
    "    print(\"%10s\" % listanomes[i],\" %8.4f    %8.4f    %8.4f    %8.4f    %8.4f\" % tuplaprint)  # imprime cada coeficiente\n",
    "\n",
    "print('\\n---------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As condições de momento do estimador de GMM são válidas?\n",
    "\n",
    "O teste J oferece uma estatística simples para verificar a \"validade\" das condições de momento do GMM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_hat = y-X @ Beta_3sls;               # resíduo da regressão do modelo \\beta_3sls\n",
    "W = inv((Z.T @ D @ Z));\n",
    "Q_n =(np.transpose(Z.T @ e_hat)) @ W @ ((Z.T @ e_hat));\n",
    "J_stat = Q_n;\n",
    "print(J_stat)\n",
    "from scipy.stats import chi2\n",
    "L=len(Z[0])\n",
    "K=len(X[0])\n",
    "df = L-K\n",
    "Jpvalue=1-chi2.cdf(J_stat, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------------------------------------------------------------------');\n",
    "print('               Teste de sobre-identificação Sargan-Hansen (J)');\n",
    "print('                       com K Graus de liberdade (gl)');\n",
    "print('-----------------------------------------------------------------------------');\n",
    "tuplaprint=(J_stat,df,Jpvalue)                       # cria uma tupla com os resultados\n",
    "print()\n",
    "print('                  J-Stat', '            gl', '             p-valor' );    \n",
    "print(\"                %8.4f         %8.4f           %8.4f\" % tuplaprint)\n",
    "print('-----------------------------------------------------------------------------');\n",
    "print('-----------------------------------------------------------------------------');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433.722px",
    "left": "1801.25px",
    "right": "20px",
    "top": "160.963px",
    "width": "503.949px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
